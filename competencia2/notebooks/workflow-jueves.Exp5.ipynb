{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Wokflow con Full Bayesiana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "Se muestra el workflow con la Bayesian Optimization diseñada para que LightGBM maximice la ganancia en pesos argentinos\n",
    "<br> En la Primera Competencia se maximizo la metrica global ROC AUC,  ahora pasamos a la metrica real que llamamos ganancia y que solo se concentra en los  11000 registros con mayor probabilidad de  {\"BAJA+1\",\"BAJA+2\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intencionalmente este notebook es un *semi-esqueleto*  al que usted deberá completar reutilizando código que ya generó para la Primera Competencia y nuevo código que resuelva las problemáticas presentes en esta competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 22:58:01 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 x 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 669447</td><td>35.8</td><td>1462271</td><td>78.1</td><td>   NA</td><td>1074203</td><td>57.4</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1249117</td><td> 9.6</td><td>8388608</td><td>64.0</td><td>32768</td><td>2010930</td><td>15.4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 x 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  669447 & 35.8 & 1462271 & 78.1 &    NA & 1074203 & 57.4\\\\\n",
       "\tVcells & 1249117 &  9.6 & 8388608 & 64.0 & 32768 & 2010930 & 15.4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 x 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |  669447 | 35.8 | 1462271 | 78.1 |    NA | 1074203 | 57.4 |\n",
       "| Vcells | 1249117 |  9.6 | 8388608 | 64.0 | 32768 | 2010930 | 15.4 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\n",
       "Ncells  669447 35.8 1462271    78.1    NA      1074203  57.4\n",
       "Vcells 1249117  9.6 8388608    64.0 32768      2010930  15.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"5.0\"\n",
    "PARAM$semilla_primigenia <- 450343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#setwd('/Users/manumoreira/Repos/dmeyf2025/competencia2/')\n",
    "#BASE_PATH <- getwd()\n",
    "#DATA_PATH <- \"../../data/competencia_02_crudo.csv.gz\"\n",
    "\n",
    "#exp_name <- sprintf(\"exp%s_seed_%d\", PARAM$experimento, PARAM$semilla_primigenia)\n",
    "#exp_dir <- file.path(BASE_PATH, \"results\", exp_name)\n",
    "#dir.create(exp_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "#setwd(exp_dir)\n",
    "\n",
    "cat(\"Working directory:\", getwd(), \"\\n\")\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))\n",
    "DATA_PATH = \"~/buckets/b1/datasets/competencia_02_crudo.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P863YZB9R1Ua",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 22:58:31 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 x 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>   775606</td><td>  41.5</td><td>   1462271</td><td>  78.1</td><td>   NA</td><td>  1462271</td><td>  78.1</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>722165493</td><td>5509.7</td><td>1017426914</td><td>7762.4</td><td>32768</td><td>846014763</td><td>6454.6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 x 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &    775606 &   41.5 &    1462271 &   78.1 &    NA &   1462271 &   78.1\\\\\n",
       "\tVcells & 722165493 & 5509.7 & 1017426914 & 7762.4 & 32768 & 846014763 & 6454.6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 x 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |    775606 |   41.5 |    1462271 |   78.1 |    NA |   1462271 |   78.1 |\n",
       "| Vcells | 722165493 | 5509.7 | 1017426914 | 7762.4 | 32768 | 846014763 | 6454.6 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   limit (Mb) max used  (Mb)  \n",
       "Ncells    775606   41.5    1462271   78.1    NA        1462271   78.1\n",
       "Vcells 722165493 5509.7 1017426914 7762.4 32768      846014763 6454.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 22:58:43 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(DATA_PATH)\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "  \"pos\" = .I,\n",
    "  numero_de_cliente,\n",
    "  periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 )\n",
    "]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "  shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente\n",
    "]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "  ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "  clase_ternaria := \"BAJA+1\"\n",
    "]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "  & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "  clase_ternaria := \"BAJA+2\"\n",
    "]\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "rm(dsimple)\n",
    "gc()\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 93 x 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>foto_mes</th><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201901</td><td>BAJA+1  </td><td>   645</td></tr>\n",
       "\t<tr><td>201901</td><td>BAJA+2  </td><td>   729</td></tr>\n",
       "\t<tr><td>201901</td><td>CONTINUA</td><td>122899</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+1  </td><td>   733</td></tr>\n",
       "\t<tr><td>201902</td><td>BAJA+2  </td><td>   707</td></tr>\n",
       "\t<tr><td>201902</td><td>CONTINUA</td><td>123961</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+1  </td><td>   708</td></tr>\n",
       "\t<tr><td>201903</td><td>BAJA+2  </td><td>   751</td></tr>\n",
       "\t<tr><td>201903</td><td>CONTINUA</td><td>124508</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+1  </td><td>   756</td></tr>\n",
       "\t<tr><td>201904</td><td>BAJA+2  </td><td>   514</td></tr>\n",
       "\t<tr><td>201904</td><td>CONTINUA</td><td>125268</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+1  </td><td>   517</td></tr>\n",
       "\t<tr><td>201905</td><td>BAJA+2  </td><td>   692</td></tr>\n",
       "\t<tr><td>201905</td><td>CONTINUA</td><td>125993</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+1  </td><td>   696</td></tr>\n",
       "\t<tr><td>201906</td><td>BAJA+2  </td><td>   608</td></tr>\n",
       "\t<tr><td>201906</td><td>CONTINUA</td><td>127430</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+1  </td><td>   611</td></tr>\n",
       "\t<tr><td>201907</td><td>BAJA+2  </td><td>   680</td></tr>\n",
       "\t<tr><td>201907</td><td>CONTINUA</td><td>128977</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+1  </td><td>   683</td></tr>\n",
       "\t<tr><td>201908</td><td>BAJA+2  </td><td>   577</td></tr>\n",
       "\t<tr><td>201908</td><td>CONTINUA</td><td>130883</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+1  </td><td>   581</td></tr>\n",
       "\t<tr><td>201909</td><td>BAJA+2  </td><td>   582</td></tr>\n",
       "\t<tr><td>201909</td><td>CONTINUA</td><td>132594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+1  </td><td>   594</td></tr>\n",
       "\t<tr><td>201910</td><td>BAJA+2  </td><td>   618</td></tr>\n",
       "\t<tr><td>201910</td><td>CONTINUA</td><td>134798</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+1  </td><td>   544</td></tr>\n",
       "\t<tr><td>202010</td><td>BAJA+2  </td><td>   454</td></tr>\n",
       "\t<tr><td>202010</td><td>CONTINUA</td><td>158171</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+1  </td><td>   456</td></tr>\n",
       "\t<tr><td>202011</td><td>BAJA+2  </td><td>   616</td></tr>\n",
       "\t<tr><td>202011</td><td>CONTINUA</td><td>159178</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202012</td><td>BAJA+2  </td><td>   619</td></tr>\n",
       "\t<tr><td>202012</td><td>CONTINUA</td><td>159756</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+2  </td><td>   825</td></tr>\n",
       "\t<tr><td>202101</td><td>CONTINUA</td><td>160080</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+1  </td><td>   831</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+2  </td><td>  1032</td></tr>\n",
       "\t<tr><td>202102</td><td>CONTINUA</td><td>160292</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+1  </td><td>  1039</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+2  </td><td>   951</td></tr>\n",
       "\t<tr><td>202103</td><td>CONTINUA</td><td>161119</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+1  </td><td>   955</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+2  </td><td>  1130</td></tr>\n",
       "\t<tr><td>202104</td><td>CONTINUA</td><td>161333</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+1  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+2  </td><td>   842</td></tr>\n",
       "\t<tr><td>202105</td><td>CONTINUA</td><td>161941</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+1  </td><td>   843</td></tr>\n",
       "\t<tr><td>202106</td><td>BAJA+2  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202106</td><td>CONTINUA</td><td>162336</td></tr>\n",
       "\t<tr><td>202107</td><td>NA      </td><td>163459</td></tr>\n",
       "\t<tr><td>202107</td><td>BAJA+1  </td><td>  1137</td></tr>\n",
       "\t<tr><td>202108</td><td>NA      </td><td>164822</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 93 x 3\n",
       "\\begin{tabular}{lll}\n",
       " foto\\_mes & clase\\_ternaria & N\\\\\n",
       " <int> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t 201901 & BAJA+1   &    645\\\\\n",
       "\t 201901 & BAJA+2   &    729\\\\\n",
       "\t 201901 & CONTINUA & 122899\\\\\n",
       "\t 201902 & BAJA+1   &    733\\\\\n",
       "\t 201902 & BAJA+2   &    707\\\\\n",
       "\t 201902 & CONTINUA & 123961\\\\\n",
       "\t 201903 & BAJA+1   &    708\\\\\n",
       "\t 201903 & BAJA+2   &    751\\\\\n",
       "\t 201903 & CONTINUA & 124508\\\\\n",
       "\t 201904 & BAJA+1   &    756\\\\\n",
       "\t 201904 & BAJA+2   &    514\\\\\n",
       "\t 201904 & CONTINUA & 125268\\\\\n",
       "\t 201905 & BAJA+1   &    517\\\\\n",
       "\t 201905 & BAJA+2   &    692\\\\\n",
       "\t 201905 & CONTINUA & 125993\\\\\n",
       "\t 201906 & BAJA+1   &    696\\\\\n",
       "\t 201906 & BAJA+2   &    608\\\\\n",
       "\t 201906 & CONTINUA & 127430\\\\\n",
       "\t 201907 & BAJA+1   &    611\\\\\n",
       "\t 201907 & BAJA+2   &    680\\\\\n",
       "\t 201907 & CONTINUA & 128977\\\\\n",
       "\t 201908 & BAJA+1   &    683\\\\\n",
       "\t 201908 & BAJA+2   &    577\\\\\n",
       "\t 201908 & CONTINUA & 130883\\\\\n",
       "\t 201909 & BAJA+1   &    581\\\\\n",
       "\t 201909 & BAJA+2   &    582\\\\\n",
       "\t 201909 & CONTINUA & 132594\\\\\n",
       "\t 201910 & BAJA+1   &    594\\\\\n",
       "\t 201910 & BAJA+2   &    618\\\\\n",
       "\t 201910 & CONTINUA & 134798\\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t 202010 & BAJA+1   &    544\\\\\n",
       "\t 202010 & BAJA+2   &    454\\\\\n",
       "\t 202010 & CONTINUA & 158171\\\\\n",
       "\t 202011 & BAJA+1   &    456\\\\\n",
       "\t 202011 & BAJA+2   &    616\\\\\n",
       "\t 202011 & CONTINUA & 159178\\\\\n",
       "\t 202012 & BAJA+1   &    622\\\\\n",
       "\t 202012 & BAJA+2   &    619\\\\\n",
       "\t 202012 & CONTINUA & 159756\\\\\n",
       "\t 202101 & BAJA+1   &    622\\\\\n",
       "\t 202101 & BAJA+2   &    825\\\\\n",
       "\t 202101 & CONTINUA & 160080\\\\\n",
       "\t 202102 & BAJA+1   &    831\\\\\n",
       "\t 202102 & BAJA+2   &   1032\\\\\n",
       "\t 202102 & CONTINUA & 160292\\\\\n",
       "\t 202103 & BAJA+1   &   1039\\\\\n",
       "\t 202103 & BAJA+2   &    951\\\\\n",
       "\t 202103 & CONTINUA & 161119\\\\\n",
       "\t 202104 & BAJA+1   &    955\\\\\n",
       "\t 202104 & BAJA+2   &   1130\\\\\n",
       "\t 202104 & CONTINUA & 161333\\\\\n",
       "\t 202105 & BAJA+1   &   1134\\\\\n",
       "\t 202105 & BAJA+2   &    842\\\\\n",
       "\t 202105 & CONTINUA & 161941\\\\\n",
       "\t 202106 & BAJA+1   &    843\\\\\n",
       "\t 202106 & BAJA+2   &   1134\\\\\n",
       "\t 202106 & CONTINUA & 162336\\\\\n",
       "\t 202107 & NA       & 163459\\\\\n",
       "\t 202107 & BAJA+1   &   1137\\\\\n",
       "\t 202108 & NA       & 164822\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 93 x 3\n",
       "\n",
       "| foto_mes &lt;int&gt; | clase_ternaria &lt;chr&gt; | N &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 201901 | BAJA+1   |    645 |\n",
       "| 201901 | BAJA+2   |    729 |\n",
       "| 201901 | CONTINUA | 122899 |\n",
       "| 201902 | BAJA+1   |    733 |\n",
       "| 201902 | BAJA+2   |    707 |\n",
       "| 201902 | CONTINUA | 123961 |\n",
       "| 201903 | BAJA+1   |    708 |\n",
       "| 201903 | BAJA+2   |    751 |\n",
       "| 201903 | CONTINUA | 124508 |\n",
       "| 201904 | BAJA+1   |    756 |\n",
       "| 201904 | BAJA+2   |    514 |\n",
       "| 201904 | CONTINUA | 125268 |\n",
       "| 201905 | BAJA+1   |    517 |\n",
       "| 201905 | BAJA+2   |    692 |\n",
       "| 201905 | CONTINUA | 125993 |\n",
       "| 201906 | BAJA+1   |    696 |\n",
       "| 201906 | BAJA+2   |    608 |\n",
       "| 201906 | CONTINUA | 127430 |\n",
       "| 201907 | BAJA+1   |    611 |\n",
       "| 201907 | BAJA+2   |    680 |\n",
       "| 201907 | CONTINUA | 128977 |\n",
       "| 201908 | BAJA+1   |    683 |\n",
       "| 201908 | BAJA+2   |    577 |\n",
       "| 201908 | CONTINUA | 130883 |\n",
       "| 201909 | BAJA+1   |    581 |\n",
       "| 201909 | BAJA+2   |    582 |\n",
       "| 201909 | CONTINUA | 132594 |\n",
       "| 201910 | BAJA+1   |    594 |\n",
       "| 201910 | BAJA+2   |    618 |\n",
       "| 201910 | CONTINUA | 134798 |\n",
       "| ... | ... | ... |\n",
       "| 202010 | BAJA+1   |    544 |\n",
       "| 202010 | BAJA+2   |    454 |\n",
       "| 202010 | CONTINUA | 158171 |\n",
       "| 202011 | BAJA+1   |    456 |\n",
       "| 202011 | BAJA+2   |    616 |\n",
       "| 202011 | CONTINUA | 159178 |\n",
       "| 202012 | BAJA+1   |    622 |\n",
       "| 202012 | BAJA+2   |    619 |\n",
       "| 202012 | CONTINUA | 159756 |\n",
       "| 202101 | BAJA+1   |    622 |\n",
       "| 202101 | BAJA+2   |    825 |\n",
       "| 202101 | CONTINUA | 160080 |\n",
       "| 202102 | BAJA+1   |    831 |\n",
       "| 202102 | BAJA+2   |   1032 |\n",
       "| 202102 | CONTINUA | 160292 |\n",
       "| 202103 | BAJA+1   |   1039 |\n",
       "| 202103 | BAJA+2   |    951 |\n",
       "| 202103 | CONTINUA | 161119 |\n",
       "| 202104 | BAJA+1   |    955 |\n",
       "| 202104 | BAJA+2   |   1130 |\n",
       "| 202104 | CONTINUA | 161333 |\n",
       "| 202105 | BAJA+1   |   1134 |\n",
       "| 202105 | BAJA+2   |    842 |\n",
       "| 202105 | CONTINUA | 161941 |\n",
       "| 202106 | BAJA+1   |    843 |\n",
       "| 202106 | BAJA+2   |   1134 |\n",
       "| 202106 | CONTINUA | 162336 |\n",
       "| 202107 | NA       | 163459 |\n",
       "| 202107 | BAJA+1   |   1137 |\n",
       "| 202108 | NA       | 164822 |\n",
       "\n"
      ],
      "text/plain": [
       "    foto_mes clase_ternaria N     \n",
       "1   201901   BAJA+1            645\n",
       "2   201901   BAJA+2            729\n",
       "3   201901   CONTINUA       122899\n",
       "4   201902   BAJA+1            733\n",
       "5   201902   BAJA+2            707\n",
       "6   201902   CONTINUA       123961\n",
       "7   201903   BAJA+1            708\n",
       "8   201903   BAJA+2            751\n",
       "9   201903   CONTINUA       124508\n",
       "10  201904   BAJA+1            756\n",
       "11  201904   BAJA+2            514\n",
       "12  201904   CONTINUA       125268\n",
       "13  201905   BAJA+1            517\n",
       "14  201905   BAJA+2            692\n",
       "15  201905   CONTINUA       125993\n",
       "16  201906   BAJA+1            696\n",
       "17  201906   BAJA+2            608\n",
       "18  201906   CONTINUA       127430\n",
       "19  201907   BAJA+1            611\n",
       "20  201907   BAJA+2            680\n",
       "21  201907   CONTINUA       128977\n",
       "22  201908   BAJA+1            683\n",
       "23  201908   BAJA+2            577\n",
       "24  201908   CONTINUA       130883\n",
       "25  201909   BAJA+1            581\n",
       "26  201909   BAJA+2            582\n",
       "27  201909   CONTINUA       132594\n",
       "28  201910   BAJA+1            594\n",
       "29  201910   BAJA+2            618\n",
       "30  201910   CONTINUA       134798\n",
       "... ...      ...            ...   \n",
       "64  202010   BAJA+1            544\n",
       "65  202010   BAJA+2            454\n",
       "66  202010   CONTINUA       158171\n",
       "67  202011   BAJA+1            456\n",
       "68  202011   BAJA+2            616\n",
       "69  202011   CONTINUA       159178\n",
       "70  202012   BAJA+1            622\n",
       "71  202012   BAJA+2            619\n",
       "72  202012   CONTINUA       159756\n",
       "73  202101   BAJA+1            622\n",
       "74  202101   BAJA+2            825\n",
       "75  202101   CONTINUA       160080\n",
       "76  202102   BAJA+1            831\n",
       "77  202102   BAJA+2           1032\n",
       "78  202102   CONTINUA       160292\n",
       "79  202103   BAJA+1           1039\n",
       "80  202103   BAJA+2            951\n",
       "81  202103   CONTINUA       161119\n",
       "82  202104   BAJA+1            955\n",
       "83  202104   BAJA+2           1130\n",
       "84  202104   CONTINUA       161333\n",
       "85  202105   BAJA+1           1134\n",
       "86  202105   BAJA+2            842\n",
       "87  202105   CONTINUA       161941\n",
       "88  202106   BAJA+1            843\n",
       "89  202106   BAJA+2           1134\n",
       "90  202106   CONTINUA       162336\n",
       "91  202107   NA             163459\n",
       "92  202107   BAJA+1           1137\n",
       "93  202108   NA             164822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
    "dataset[, .N, list(foto_mes, clase_ternaria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar a gusto LUEGO de realizar un analisis exploratorio de datos.\n",
    "<br> No necesariamente en esta Segunda Competencia conviele eliminar los mismos campos que en la Primera ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 22:58:44 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[, mprestamos_personales := NULL ]\n",
    "dataset[, cprestamos_personales := NULL ]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deben reparar los atributos del dataset que para un cierto mes TODOS sus valores son cero.\n",
    "<br> Relevar en forma muy minuciosa en el dataset cuales son los  <atributo,mes> que estan dañados.\n",
    "<br> Algunas alternativas de solución son:\n",
    "* No hacer absolutamente nada, dejar el valor 0 tal cual está, a sabiendas que es incorrecto\n",
    "* Reemplazar esos valores dañados por  NA\n",
    "* Interpolar cada valor dañado por el valor del mes previo y el posterior\n",
    "* Calcularlo a partir de un modelo, libreria  MICE\n",
    "\n",
    "a este codigo de Data Quality  lo debera escribir usted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     foto_mes                column_name\n",
      "        <int>                     <char>\n",
      "  1:   201901                tmobile_app\n",
      "  2:   201901            cmobile_app_trx\n",
      "  3:   201902                tmobile_app\n",
      "  4:   201902            cmobile_app_trx\n",
      "  5:   201903                tmobile_app\n",
      " ---                                    \n",
      "103:   202102   ctarjeta_visa_descuentos\n",
      "104:   202102   mtarjeta_visa_descuentos\n",
      "105:   202102 ctarjeta_master_descuentos\n",
      "106:   202102 mtarjeta_master_descuentos\n",
      "107:   202105           ccajas_depositos\n"
     ]
    }
   ],
   "source": [
    "# Busco los features que tienen full_zero menos foto_mes y numero_de_cliente (preventivo)\n",
    "numeric_cols <- names(dataset)[sapply(dataset, is.numeric)]\n",
    "numeric_cols <- setdiff(numeric_cols, c(\"foto_mes\", \"numero_de_cliente\"))\n",
    "\n",
    "result_list <- list()\n",
    "\n",
    "for(month in unique(dataset$foto_mes)) {\n",
    "  month_data <- dataset[foto_mes == month, ..numeric_cols]\n",
    "  \n",
    "  # TODO CERO\n",
    "  zero_cols <- numeric_cols[sapply(month_data, function(x) all(x == 0, na.rm = TRUE))]\n",
    "  \n",
    "  if(length(zero_cols) > 0) {\n",
    "    result_list[[as.character(month)]] <- data.table(\n",
    "      foto_mes = month,\n",
    "      column_name = zero_cols\n",
    "    )\n",
    "  }\n",
    "}\n",
    "\n",
    "vars_full_zero <- rbindlist(result_list)\n",
    "print(vars_full_zero)\n",
    "\n",
    "# Aplico NULL \n",
    "for(month in unique(vars_full_zero$foto_mes)){\n",
    "  vars_this_month <- vars_full_zero[foto_mes == month, column_name]\n",
    "  \n",
    "  dataset[foto_mes == month,\n",
    "          (vars_this_month) := lapply(.SD, function(x) ifelse(x == 0, NA, x)),\n",
    "          .SDcols = vars_this_month]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Drifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe corregir el drifting natural que ocurre en loa datos, en particular los datos monetarios que se vieron fuertemente afectados por una alta inflación\n",
    "<br> Posibles métodos son:\n",
    "* No hacer absolutamente nada\n",
    "* Ajuste de valores monetarios por indices del tipo :\n",
    "   * IPC  Indice de Precios al Consumidor\n",
    "   * Dolar Oficial\n",
    "   * Dolar Blue\n",
    "   * UVA  Unidad de Valor Adquisitivo\n",
    "\n",
    "a este codigo de Data Drifting lo debera escribir usted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking con cero fijo y respetando NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "drift_rank_zero <- function(dt, vars_drift, month_col = \"foto_mes\") {\n",
    "  for (var in vars_drift) {\n",
    "    new_col <- paste0(var, \"_rank\")\n",
    "    \n",
    "    # Inicializo con NULL\n",
    "    dt[, (new_col) := NA_real_]\n",
    "    \n",
    "    # ranking con cero fijo y sin alterar los NULL\n",
    "    dt[!is.na(get(var)) & get(var) == 0, (new_col) := 0]\n",
    "    dt[!is.na(get(var)) & get(var) > 0, (new_col) := frank(get(var), ties.method = \"random\") / .N, by = get(month_col)]\n",
    "    dt[!is.na(get(var)) & get(var) < 0, (new_col) := -frank(-get(var), ties.method = \"random\") / .N, by = get(month_col)]\n",
    "  # borrar originales\n",
    "  # dt[, (var) := NULL]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "drift_rank_zero(dataset, c(\"mrentabilidad\", \"mrentabilidad_annual\", \"mcomisiones\", \"mactivos_margen\", \"mpasivos_margen\", \n",
    "                \"mcuenta_corriente_adicional\", \"mcuenta_corriente\", \"mcaja_ahorro\", \"mcaja_ahorro_adicional\", \n",
    "                \"mcaja_ahorro_dolares\", \"mcuentas_saldo\", \"mautoservicio\", \"mtarjeta_visa_consumo\", \"mtarjeta_master_consumo\", \n",
    "                \"mprestamos_prendarios\", \"mprestamos_hipotecarios\", \"mplazo_fijo_dolares\", \n",
    "                \"mplazo_fijo_pesos\", \"minversion1_pesos\", \"minversion1_dolares\", \"minversion2\", \"mpayroll\", \"mpayroll2\", \n",
    "                \"mcuenta_debitos_automaticos\", \"mttarjeta_visa_debitos_automaticos\", \"mttarjeta_master_debitos_automaticos\", \n",
    "                \"mpagodeservicios\", \"mpagomiscuentas\", \"mcajeros_propios_descuentos\", \"mtarjeta_visa_descuentos\", \n",
    "                \"mtarjeta_master_descuentos\", \"mcomisiones_mantenimiento\", \"mcomisiones_otras\", \"mforex_buy\", \"mforex_sell\", \n",
    "                \"mtransferencias_recibidas\", \"mtransferencias_emitidas\", \"mextraccion_autoservicio\", \"mcheques_depositados\", \n",
    "                \"mcheques_emitidos\", \"mcheques_depositados_rechazados\", \"mcheques_emitidos_rechazados\", \"matm\", \"matm_other\", \n",
    "                \"Master_mfinanciacion_limite\", \"Master_msaldototal\", \"Master_msaldopesos\", \"Master_msaldodolares\", \n",
    "                \"Master_mconsumospesos\", \"Master_mconsumosdolares\", \"Master_mlimitecompra\", \"Master_madelantopesos\", \n",
    "                \"Master_madelantodolares\", \"Master_mpagado\", \"Master_mpagospesos\", \"Master_mpagosdolares\", \n",
    "                \"Master_mconsumototal\", \"Master_mpagominimo\", \"Visa_mfinanciacion_limite\", \"Visa_msaldototal\", \n",
    "                \"Visa_msaldopesos\", \"Visa_msaldodolares\", \"Visa_mconsumospesos\", \"Visa_mconsumosdolares\", \n",
    "                \"Visa_mlimitecompra\", \"Visa_madelantopesos\", \"Visa_madelantodolares\", \"Visa_mpagado\", \"Visa_mpagospesos\", \n",
    "                \"Visa_mpagosdolares\", \"Visa_mconsumototal\", \"Visa_mpagominimo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Intra-Mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear variables nuevas a partir de las existentes dentro del mismo registro, **sin** ir a buscar información histórica.\n",
    "<br> El siguiente código es un mínimo ejemplo, agregar nuevos features a gusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 23:00:21 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# el mes 1,2, ..12 , podria servir para detectar estacionalidad\n",
    "dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# creo un ctr_quarter que tenga en cuenta cuando\n",
    "# los clientes hace 3 menos meses que estan\n",
    "# ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
    "dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
    "dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5.0]\n",
    "dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2.0]\n",
    "dataset[cliente_antiguedad == 3, ctrx_quarter_normalizado := ctrx_quarter * 1.2]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda, se perdió el link\n",
    "dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-11 23:01:57 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Consumo vs límite\n",
    "dataset[, visa_consumo_sobre_limite := Visa_mconsumototal / pmax(Visa_mlimitecompra, 1)]\n",
    "dataset[, master_consumo_sobre_limite := Master_mconsumototal / pmax(Master_mlimitecompra, 1)]\n",
    "\n",
    "# Pago vs consumo (indica si paga completo o financia)\n",
    "dataset[, visa_pct_pago := Visa_mpagado / pmax(Visa_mconsumototal, 1)]\n",
    "dataset[, master_pct_pago := Master_mpagado / pmax(Master_mconsumototal, 1)]\n",
    "\n",
    "# Ratio de rechazo\n",
    "dataset[, ratio_cheques_rechazados_emitidos := ccheques_emitidos_rechazados / \n",
    "         pmax(ccheques_emitidos, 1)]\n",
    "dataset[, ratio_cheques_rechazados_depositados := ccheques_depositados_rechazados / \n",
    "         pmax(ccheques_depositados, 1)]\n",
    "\n",
    "# Rentabilidad por producto/antigüedad\n",
    "dataset[, rentabilidad_por_producto := mrentabilidad / pmax(cproductos, 1)]\n",
    "dataset[, rentabilidad_por_antiguedad := mrentabilidad_annual / pmax(cliente_antiguedad, 1)]\n",
    "dataset[, comisiones_sobre_rentabilidad := mcomisiones / pmax(mrentabilidad, 1)]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"Rcpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se calculan para los 6 meses previos el minimo, maximo y\n",
    "#  tendencia calculada con cuadrados minimos\n",
    "# la formula de calculo de la tendencia puede verse en\n",
    "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
    "# y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) )\n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      {\n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ;\n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ;\n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas <- function(\n",
    "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
    "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
    "    ratioavg = FALSE, ratiomax = FALSE) {\n",
    "  gc(verbose= FALSE)\n",
    "  # Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion <- ventana\n",
    "\n",
    "  last <- nrow(dataset)\n",
    "\n",
    "  # creo el vector_desde que indica cada ventana\n",
    "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids <- dataset[ , numero_de_cliente ]\n",
    "\n",
    "  vector_desde <- seq(\n",
    "    -ventana_regresion + 2,\n",
    "    nrow(dataset) - ventana_regresion + 1\n",
    "  )\n",
    "\n",
    "  vector_desde[1:ventana_regresion] <- 1\n",
    "\n",
    "  for (i in 2:last) {\n",
    "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
    "      vector_desde[i] <- i\n",
    "    }\n",
    "  }\n",
    "  for (i in 2:last) {\n",
    "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
    "      vector_desde[i] <- vector_desde[i - 1]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for (campo in cols) {\n",
    "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
    "\n",
    "    if (tendencia) {\n",
    "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
    "        nueva_col[(0 * last + 1):(1 * last)]]\n",
    "    }\n",
    "\n",
    "    if (minimo) {\n",
    "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
    "        nueva_col[(1 * last + 1):(2 * last)]]\n",
    "    }\n",
    "\n",
    "    if (maximo) {\n",
    "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
    "        nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "\n",
    "    if (promedio) {\n",
    "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
    "        nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratioavg) {\n",
    "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
    "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratiomax) {\n",
    "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
    "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# parametros de Feature Engineering Historico de Tendencias\n",
    "PARAM$FE_hist$Tendencias$run <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ventana <- 6\n",
    "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
    "PARAM$FE_hist$Tendencias$minimo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$maximo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$promedio <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratioavg <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratiomax <- FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aqui se agregan las tendencias de los ultimos 6 meses\n",
    "\n",
    "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "if( PARAM$FE_hist$Tendencias$run) {\n",
    "    TendenciaYmuchomas(dataset,\n",
    "    cols = cols_lagueables,\n",
    "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
    "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
    "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
    "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
    "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
    "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
    "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
    "  )\n",
    "}\n",
    "\n",
    "ncol(dataset)\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering a partir de hojas de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add memory monitoring at the beginning\n",
    "monitor_memory <- function() {\n",
    "  if (Sys.info()[\"sysname\"] == \"Darwin\") {  # macOS\n",
    "    mem_info <- system(\"vm_stat\", intern = TRUE)\n",
    "    cat(\"Memory info:\\n\")\n",
    "    cat(mem_info[1:10], sep = \"\\n\")\n",
    "  }\n",
    "  print(gc())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "AgregaVarRandomForest <- function() {\n",
    "\n",
    "  monitor_memory()\n",
    "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
    "  gc(verbose= FALSE)\n",
    "  dataset[, clase01 := 0L ]\n",
    "  dataset[ clase_ternaria %in% c( \"BAJA+2\", \"BAJA+1\"),\n",
    "      clase01 := 1L ]\n",
    "\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c( \"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "\n",
    "  dataset[, entrenamiento :=\n",
    "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
    "\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
    "    label = dataset[entrenamiento == TRUE, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "\n",
    "  modelo <- lgb.train(\n",
    "     data = dtrain,\n",
    "     param = PARAM$FE_rf$lgb_param,\n",
    "     verbose = -100\n",
    "  )\n",
    "\n",
    "  cat( \"Fin construccion RandomForest\\n\" )\n",
    "  # grabo el modelo, achivo .model\n",
    "  lgb.save(modelo, file=\"modelo.model\" )\n",
    "\n",
    "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
    "\n",
    "  periodos <- dataset[ , unique( foto_mes ) ]\n",
    "\n",
    "  for( periodo in  periodos )\n",
    "  {\n",
    "    cat( \"periodo = \", periodo, \"\\n\" )\n",
    "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
    "\n",
    "    cat( \"Inicio prediccion\\n\" )\n",
    "    prediccion <- predict(\n",
    "        modelo,\n",
    "        datamatrix,\n",
    "        type = \"leaf\"\n",
    "    )\n",
    "    cat( \"Fin prediccion\\n\" )\n",
    "\n",
    "    for( arbolito in 1:qarbolitos )\n",
    "    {\n",
    "       cat( arbolito, \" \" )\n",
    "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
    "\n",
    "       for (pos in 1:length(hojas_arbol)) {\n",
    "         # el numero de nodo de la hoja, estan salteados\n",
    "         nodo_id <- hojas_arbol[pos]\n",
    "         dataset[ foto_mes== periodo, paste0(\n",
    "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
    "             \"_\", sprintf(\"%03d\", nodo_id)\n",
    "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
    "\n",
    "       }\n",
    "\n",
    "       rm( hojas_arbol )\n",
    "    }\n",
    "    cat( \"\\n\" )\n",
    "\n",
    "    rm( prediccion )\n",
    "    rm( datamatrix )\n",
    "    gc(verbose= FALSE)\n",
    "  }\n",
    "\n",
    "  gc(verbose= FALSE)\n",
    "\n",
    "  # borro clase01 , no debe ensuciar el dataset\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Parametros de Feature Engineering a partir de hojas de Random Forest\n",
    "\n",
    "# Estos CUATRO parametros son los que se deben modificar\n",
    "PARAM$FE_rf$arbolitos= 20\n",
    "PARAM$FE_rf$hojas_por_arbol= 16\n",
    "PARAM$FE_rf$datos_por_hoja= 100\n",
    "PARAM$FE_rf$mtry_ratio= 0.2\n",
    "\n",
    "# Estos son quasi fijos\n",
    "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
    "\n",
    "# Estos TAMBIEN son quasi fijos\n",
    "PARAM$FE_rf$lgb_param <-list(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = PARAM$FE_rf$arbolitos,\n",
    "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
    "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
    "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1.0,\n",
    "    feature_fraction = 1.0,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31L,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    force_row_wise = TRUE,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1L,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = FALSE,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = FALSE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering agregando variables de Random Forest\n",
    "#  aqui es donde se hace el trabajo\n",
    "AgregaVarRandomForest()\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ncol(dataset)\n",
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduccion dimensionalidad con canaritos asesinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intencionalmente este código no se brinda\n",
    "<br> El objetivo de esto es reducir la dimensionalidad del dataset unicamente para que la Bayesian Optimization corra mas rápido\n",
    "<br> Tambien se puede probar con Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros generales\n",
    "PARAM$canaritos$future <- c(202104)\n",
    "PARAM$canaritos$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103\n",
    ")\n",
    "PARAM$canaritos$undersampling <- 0.10\n",
    "PARAM$canaritos$ratio <- 0.05\n",
    "PARAM$canaritos$semilla_base <- PARAM$semilla_primigenia\n",
    "PARAM$canaritos$num_runs <- 5\n",
    "PARAM$canaritos$semillas <- c(450343, 450421, 450599, 862019, 862013)\n",
    "PARAM$canaritos$desvios <- 2\n",
    "\n",
    "\n",
    "# Preparar dataset\n",
    "dataset_canaritos_train <- dataset[foto_mes %in% PARAM$canaritos$training]\n",
    "\n",
    "# Undersampling\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_canaritos_train[, azar := runif(nrow(dataset_canaritos_train))]\n",
    "dataset_canaritos_train[, training := 0L]\n",
    "dataset_canaritos_train[\n",
    "  (azar <= PARAM$canaritos$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "dataset_canaritos_train[, azar := NULL]\n",
    "\n",
    "# Clase binaria\n",
    "dataset_canaritos_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\", \"BAJA+1\"), 1L, 0L)\n",
    "]\n",
    "\n",
    "cat(\"Registros training:\", dataset_canaritos_train[training == 1L, .N], \"\\n\")\n",
    "\n",
    "# Crear canaritos\n",
    "cols_original <- copy(colnames(dataset_canaritos_train))\n",
    "PARAM$canaritos$qcanaritos <- max(1, round((ncol(dataset_canaritos_train) - 4) * PARAM$canaritos$ratio))\n",
    "\n",
    "cat(\"Agregando\", PARAM$canaritos$qcanaritos, \"canaritos\\n\")\n",
    "\n",
    "filas <- nrow(dataset_canaritos_train)\n",
    "set.seed(PARAM$canaritos$semilla_base, kind = \"L'Ecuyer-CMRG\")\n",
    "for (i in seq(PARAM$canaritos$qcanaritos)) {\n",
    "  dataset_canaritos_train[, paste0(\"canarito_\", i) := runif(filas)]\n",
    "}\n",
    "\n",
    "cols_canaritos <- setdiff(colnames(dataset_canaritos_train), cols_original)\n",
    "setcolorder(dataset_canaritos_train, c(cols_canaritos, cols_original))\n",
    "\n",
    "# Preparar campos para el modelo\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_canaritos_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"training\")\n",
    ")\n",
    "\n",
    "cat(\"Total features:\", length(campos_buenos), \"(\", length(cols_canaritos), \"canaritos +\", \n",
    "    length(campos_buenos) - length(cols_canaritos), \"reales)\\n\")\n",
    "\n",
    "# Preparar dataset de LightGBM\n",
    "dcanaritos_train <- lgb.Dataset(\n",
    "  data = data.matrix(dataset_canaritos_train[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label = dataset_canaritos_train[training == 1L, clase01],\n",
    "  free_raw_data = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "params <- list(\n",
    "  objective = \"binary\",\n",
    "  boost_from_average = TRUE,\n",
    "  feature_pre_filter = FALSE,\n",
    "  verbosity = -1,\n",
    "  max_depth = -1,\n",
    "  min_gain_to_split = 0.0,\n",
    "  lambda_l1 = 0.0,\n",
    "  lambda_l2 = 0.0,\n",
    "  max_bin = 31,\n",
    "  force_row_wise = TRUE,\n",
    "  learning_rate = 0.1,\n",
    "  feature_fraction = 1.0,\n",
    "  bagging_fraction = 0.8,\n",
    "  bagging_freq = 5,\n",
    "  min_data_in_leaf = 50,\n",
    "  num_leaves = 31,\n",
    "  num_threads = 1\n",
    ")\n",
    "\n",
    "cat(\"\\n--- Entrenando\", PARAM$canaritos$num_runs, \"modelos ---\\n\")\n",
    "\n",
    "importance_list <- list()\n",
    "\n",
    "for (run in 1:PARAM$canaritos$num_runs) {\n",
    "  cat(\"Run\", run, \"... \")\n",
    "  \n",
    "  params$seed <- PARAM$canaritos$semillas[run]\n",
    "  \n",
    "  model <- lgb.train(\n",
    "    data = dcanaritos_train,\n",
    "    params = params,\n",
    "    nrounds = 200,\n",
    "    verbose = -1\n",
    "  )\n",
    "  \n",
    "  tb_importancia <- lgb.importance(model)\n",
    "  tb_importancia[, run := run]\n",
    "  importance_list[[run]] <- tb_importancia\n",
    "  \n",
    "  cat(\"OK (\", nrow(tb_importancia), \"features)\\n\", sep = \"\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n--- Promediando importancia ---\\n\")\n",
    "\n",
    "dt_importance_all <- rbindlist(importance_list)\n",
    "\n",
    "tb_importancia <- dt_importance_all[, .(\n",
    "  Gain = mean(Gain),\n",
    "  Cover = mean(Cover),\n",
    "  Frequency = mean(Frequency)\n",
    "), by = Feature]\n",
    "\n",
    "setorder(tb_importancia, -Gain)\n",
    "tb_importancia[, position := .I]\n",
    "tb_importancia[, es_canarito := grepl(\"^canarito_\", Feature)]\n",
    "\n",
    "cat(\"Features con importancia:\", nrow(tb_importancia), \"\\n\")\n",
    "cat(\"Canaritos encontrados:\", sum(tb_importancia$es_canarito), \"\\n\")\n",
    "\n",
    "if (sum(tb_importancia$es_canarito) == 0) {\n",
    "  stop(\"ERROR: No se encontraron canaritos en la importancia.\")\n",
    "}\n",
    "\n",
    "canary_positions <- tb_importancia[es_canarito == TRUE, position]\n",
    "\n",
    "cat(\"\\nPosiciones canaritos - Min:\", min(canary_positions), \n",
    "    \"| Median:\", median(canary_positions), \n",
    "    \"| Max:\", max(canary_positions), \n",
    "    \"| SD:\", round(sd(canary_positions), 2), \"\\n\")\n",
    "\n",
    "threshold <- round(median(canary_positions) + PARAM$canaritos$desvios * sd(canary_positions))\n",
    "\n",
    "cat(\"Threshold (desvios =\", PARAM$canaritos$desvios, \"):\", threshold, \"\\n\")\n",
    "\n",
    "# Features a eliminar y mantener\n",
    "features_to_remove <- tb_importancia[position > threshold & es_canarito == FALSE, Feature]\n",
    "features_to_keep <- tb_importancia[position <= threshold & es_canarito == FALSE, Feature]\n",
    "\n",
    "cat(\"\\n--- Resultados ---\\n\")\n",
    "cat(\"Features a mantener:\", length(features_to_keep), \"\\n\")\n",
    "cat(\"Features a eliminar:\", length(features_to_remove), \"\\n\")\n",
    "cat(\"Reducción:\", round(100 * length(features_to_remove) / \n",
    "                         (nrow(tb_importancia) - length(cols_canaritos)), 1), \"%\\n\")\n",
    "\n",
    "cat(\"\\n--- Guardando archivos ---\\n\")\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "       file = \"canaritos_importance.txt\",\n",
    "       sep = \"\\t\")\n",
    "\n",
    "fwrite(data.table(Feature = features_to_keep),\n",
    "       file = \"canaritos_features_mantener.txt\",\n",
    "       sep = \"\\t\")\n",
    "\n",
    "if (length(features_to_remove) > 0) {\n",
    "  fwrite(data.table(Feature = features_to_remove),\n",
    "         file = \"canaritos_features_eliminar.txt\",\n",
    "         sep = \"\\t\")\n",
    "}\n",
    "\n",
    "# Calcular valores con seguridad\n",
    "n_features_originales <- length(campos_buenos) - length(cols_canaritos)\n",
    "n_canaritos <- length(cols_canaritos)\n",
    "n_features_reales_con_importancia <- nrow(tb_importancia) - sum(tb_importancia$es_canarito)\n",
    "\n",
    "reduccion_pct <- if (n_features_reales_con_importancia > 0) {\n",
    "  round(100 * length(features_to_remove) / n_features_reales_con_importancia, 1)\n",
    "} else {\n",
    "  0\n",
    "}\n",
    "\n",
    "resumen <- data.table(\n",
    "  metrica = c(\"features_originales\", \"canaritos\", \"threshold\", \n",
    "              \"features_mantener\", \"features_eliminar\", \"reduccion_pct\"),\n",
    "  valor = c(\n",
    "    n_features_originales,\n",
    "    n_canaritos,\n",
    "    threshold,\n",
    "    length(features_to_keep),\n",
    "    length(features_to_remove),\n",
    "    reduccion_pct\n",
    "  )\n",
    ")\n",
    "\n",
    "fwrite(resumen,\n",
    "       file = \"canaritos_resumen.txt\",\n",
    "       sep = \"\\t\")\n",
    "\n",
    "cat(\"Archivos guardados\\n\")\n",
    "cat(\"\\n=== PROCESO COMPLETADO ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cat(\"\\n--- Aplicando eliminación de features ---\\n\")\n",
    "\n",
    "# Verificar que dataset existe y tiene las columnas\n",
    "cat(\"Columnas en dataset original:\", ncol(dataset), \"\\n\")\n",
    "\n",
    "# Eliminar features seleccionadas\n",
    "if (length(features_to_remove) > 0) {\n",
    "  # Verificar que las features existen en el dataset\n",
    "  features_existentes <- intersect(features_to_remove, colnames(dataset))\n",
    "  features_no_existentes <- setdiff(features_to_remove, colnames(dataset))\n",
    "  \n",
    "  if (length(features_no_existentes) > 0) {\n",
    "    cat(\"WARNING:\", length(features_no_existentes), \"features no encontradas en dataset\\n\")\n",
    "  }\n",
    "  \n",
    "  if (length(features_existentes) > 0) {\n",
    "    dataset[, (features_existentes) := NULL]\n",
    "    cat(\"✓\", length(features_existentes), \"features eliminadas\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"No hay features para eliminar\\n\")\n",
    "}\n",
    "\n",
    "# Eliminar canaritos\n",
    "canaritos_en_dataset <- intersect(cols_canaritos, colnames(dataset))\n",
    "if (length(canaritos_en_dataset) > 0) {\n",
    "  dataset[, (canaritos_en_dataset) := NULL]\n",
    "  cat(\"✓ Canaritos eliminados\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\nColumnas finales en dataset:\", ncol(dataset), \"\\n\")\n",
    "cat(\"Reducción total:\", ncol(dataset_canaritos_train) - 4 - ncol(dataset), \"columnas\\n\")\n",
    "\n",
    "cat(\"\\n=== CANARITOS FINALIZADO ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
    "\n",
    "* future = 202108  obviamente completo\n",
    "\n",
    "* final_train =  [201901, 202106] sin undersampling de los CONTINUA\n",
    "\n",
    "* training\n",
    "   * testing = 202106\n",
    "   * training = [201901, 202104]  donde se consideran el 5% de los CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$testing <- c(202104)\n",
    "\n",
    "PARAM$trainingstrategy$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103\n",
    ")\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.05\n",
    "\n",
    "\n",
    "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# los campos en los que se entrena\n",
    "campos_buenos <- copy( setdiff(\n",
    "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros  cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "\n",
    "dataset[  foto_mes %in%  PARAM$trainingstrategy$training &\n",
    "  (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se optimizan los hiperparámetros maximizando la ganancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label= dataset[training == 1L, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain), \"columnas\", ncol(dtrain), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset_test <- dataset[foto_mes %in% PARAM$trainingstrategy$testing]\n",
    "\n",
    "# precalculo el campo de la ganancia\n",
    "dataset_test[, gan := -20000.0 ]\n",
    "dataset_test[ clase_ternaria==\"BAJA+2\", gan := 780000]\n",
    "\n",
    "# precalculo la test_matrix\n",
    "test_matrix <- data.matrix(dataset_test[, campos_buenos, with= FALSE])\n",
    "\n",
    "cat(\"filas\", nrow(dataset_test), \"columnas\", ncol(dataset_test), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Especificacion de la cantidad de iteraciones de la Bayesian Optimization\n",
    "# 50 es razonable\n",
    "PARAM$hipeparametertuning$BO_iteraciones <- 50 # un 50 seria mas razonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  extra_trees = FALSE,\n",
    "\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  max_bin= 31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Notar que se recorren algunos hiperparametros en forma logaritmica\n",
    "#   y que con forbidden se tiene en cuenta el juego que hay entre min_data_in_leaf y num_leaves\n",
    "\n",
    "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
    "  makeNumericParam(\"num_iterations\", lower= 0.0, upper= 11.1, trafo= function(x) as.integer( round(2^x)) ),\n",
    "  makeNumericParam(\"learning_rate\", lower= -8.0, upper= -1.0, trafo= function(x) 2^x ),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.05, upper= 1.0 ),\n",
    "  makeNumericParam(\"min_data_in_leaf\", lower= 0.0, upper= log2(nrow(dtrain)/2), trafo= function(x) as.integer(round(2^x)) ),\n",
    "  makeNumericParam(\"num_leaves\", lower= 1.0, upper= 10.0, trafo= function(x) as.integer(round(2^x)) ),\n",
    "  forbidden= quote( (2^min_data_in_leaf)*(2^num_leaves) > nrow(dtrain) )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro **ksemillerio** indica se se hace semillerio DENTRO de la bayesiana\n",
    "* 1 **no** se hace Ensemble Semillerio, apenas se corre un solo LightGBM\n",
    "* mayor a 1, se hace un  k-Ensemble Semillerio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro  **repe** indica si dentro de la bayesiana se toman varias medidas y luego se promedian\n",
    "<br> Esto se hace ya sea que se llama a un solo LightGBM o se haceun Ensemble Semillerio de LightGBMs\n",
    "<br> Tener en cuenta que repe multiplica linealmente el tiempo de corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$hipeparametertuning$ksemillerio <- 5L\n",
    "PARAM$hipeparametertuning$repe <- 1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "# me quedo con PARAM$semillerio  primos al azar\n",
    "PARAM$BO$semillas <- sample(primos)[seq( PARAM$hipeparametertuning$ksemillerio * PARAM$hipeparametertuning$repe )]\n",
    "\n",
    "cat( PARAM$BO$semillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!require(\"rlist\")) install.packages(\"rlist\")\n",
    "require(\"rlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# logueo al archivo BO_log.txt\n",
    "loguear  <- function( reg, arch=NA, verbose=TRUE )\n",
    "{\n",
    "  t0 <- Sys.time()\n",
    "  archivo <- arch\n",
    "  if( is.na(arch) ) archivo <- paste0( folder, substitute( reg), ext )\n",
    "\n",
    "\n",
    "  if( !file.exists( archivo ) )\n",
    "  {\n",
    "    # Escribo los titulos\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  # escribo el registro\n",
    "  linea  <- paste0( format(t0, \"%Y%m%d.%H%M%S\"),  \"\\t\",     # la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  # grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# esto esta en una funcion para que el garbage collector lo libere\n",
    "# entrena, aplica el modelo a testing, y devuelve el vector de probabilidades\n",
    "\n",
    "OneTrainPredict <- function(param_completo) {\n",
    "    \n",
    "  modelo <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_completo\n",
    "  )\n",
    "  gmodelo <<- modelo\n",
    "\n",
    "  # aplico el modelo a los datos nuevos\n",
    "  pred <- predict(\n",
    "    modelo,\n",
    "    test_matrix\n",
    "  )\n",
    "\n",
    "  return( pred )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la ganancia en datos de testing\n",
    "\n",
    "# aqui se ira guardando la mejor iteracion de la bayesiana\n",
    "gmejor <- list()\n",
    "gmejor$iter <- 0\n",
    "gmejor$gan <- -Inf\n",
    "\n",
    "giter <- 0\n",
    "if( file.exists(\"BO_log.txt\") ){\n",
    "  tb_BO <- fread(\"BO_log.txt\")\n",
    "  giter <- nrow(tb_BO) -1 \n",
    "}\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "\n",
    "  giter <<- giter + 1\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  vgan_mesetas <- c()  # las ganancias, tengo repe de ellas\n",
    "\n",
    "  # GUARDO DATOS PARA LA CURVA DE GANANCIA\n",
    "  gain_data_list <- list()\n",
    "\n",
    "  # loop de las repeticionies\n",
    "  for( repe in seq( PARAM$hipeparametertuning$repe ) )\n",
    "  {\n",
    "     desde <- (PARAM$hipeparametertuning$repe-1)*PARAM$hipeparametertuning$ksemillerio + 1\n",
    "     hasta <- desde + PARAM$hipeparametertuning$ksemillerio -1\n",
    "     rsemillas <- PARAM$BO$semillas[ desde:hasta ]\n",
    "\n",
    "     # vector inicial de probabilidades\n",
    "     vpred_acum <- rep( 0.0, nrow(dataset_test) )\n",
    "\n",
    "     # loop del semillerio\n",
    "     for( sem in rsemillas ) # itero semillerio\n",
    "     {\n",
    "        param_completo$seed <- sem  # asigno se semilla\n",
    "        vpred_acum <- vpred_acum + OneTrainPredict( param_completo )\n",
    "        \n",
    "        gc(full= TRUE, verbose= FALSE)\n",
    "     }\n",
    "\n",
    "     # Calculo de ganancia suavizada de la meseta\n",
    "     tb_prediccion <- dataset_test[, list(gan)]\n",
    "     tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "     setorder(tb_prediccion, -prob)\n",
    "     tb_prediccion[, gan_acum := cumsum(gan)]\n",
    "\n",
    "     # la meseta es un punto, mil para la izquierda, otros mil para la derecha\n",
    "     tb_prediccion[, gan_meseta :=\n",
    "       frollmean(\n",
    "         x= gan_acum, n= 2001, align= \"center\",\n",
    "         na.rm= TRUE, hasNA= TRUE\n",
    "      )\n",
    "     ]\n",
    "    \n",
    "    # CREO UNA TABLA PARA GUARDAR LOS DATOS DE GANANCIA\n",
    "    tb_gain_analysis <- copy(tb_prediccion)  \n",
    "    \n",
    "    # Sigo cargando meta-data\n",
    "    tb_gain_analysis[, repe := repe]\n",
    "    tb_gain_analysis[, iter := giter]\n",
    "    gain_data_list[[repe]] <- tb_gain_analysis \n",
    "\n",
    "    vgan_mesetas <- c(vgan_mesetas, tb_prediccion[, max(gan_meseta, na.rm = TRUE)] )\n",
    "  }\n",
    "  # Grabo en archivo\n",
    "  if(length(gain_data_list) > 0) {\n",
    "    all_gain_data <- rbindlist(gain_data_list)\n",
    "    fwrite(all_gain_data, file = paste0(\"gain_data_iter_\", giter, \".csv\"))}\n",
    "\n",
    "  gan_mesetas_prom <- mean( vgan_mesetas ) \n",
    "\n",
    "  if( gan_mesetas_prom > gmejor$gan ){\n",
    "    gmejor$gan <<- gan_mesetas_prom\n",
    "    gmejor$iter <<- giter\n",
    "\n",
    "    # hrabo importancia de variables\n",
    "    fwrite( lgb.importance(gmodelo),\n",
    "      file= paste0(\"impo_\", giter, \".txt\"),\n",
    "      sep= \"\\t\"\n",
    "    )\n",
    "  }\n",
    "\n",
    "  # datos qeu voy a loguear\n",
    "  xx <- copy(param_completo)\n",
    "  xx$iter <- giter\n",
    "  xx$metrica_mejor <- gmejor$gan\n",
    "  xx$metrica_sd <- sd(vgan_mesetas)\n",
    "  xx$metrica <- gan_mesetas_prom\n",
    "\n",
    "  loguear( xx, \"BO_log.txt\")\n",
    "  set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")  # le reordeno a mlrMBO\n",
    "\n",
    "  return( gan_mesetas_prom ) #tiempo_corrida) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "#  es compleja la configuracion de una Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hipeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hipeparametertuning$BO_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficar curvas de ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"ggplot2\")) install.packages(\"ggplot2\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"ggplot2\")\n",
    "if( !require(\"dplyr\")) install.packages(\"dplyr\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"dplyr\")\n",
    "if( !require(\"gridExtra\")) install.packages(\"gridExtra\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"gridExtra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "generate_final_charts <- function() {\n",
    "  # Buscar los archivos de ganancia\n",
    "  gain_files <- list.files(pattern = \"gain_data_iter_.*\\\\.csv\")\n",
    "  \n",
    "  if(length(gain_files) > 0) {\n",
    "    # Cargo la data\n",
    "    all_iter_data <- rbindlist(lapply(gain_files, fread))\n",
    "    \n",
    "    # Remove NA values from gan_meseta\n",
    "    all_iter_data <- all_iter_data[!is.na(gan_meseta)]\n",
    "    \n",
    "    # Chart 1: La mejor ganancia en cada iteracion\n",
    "    best_by_iter <- all_iter_data[, .(best_gain = max(gan_meseta, na.rm = TRUE)), by = iter]\n",
    "    \n",
    "    p_evolution <- ggplot(best_by_iter, aes(x = iter, y = best_gain)) +\n",
    "      geom_line(color = \"blue\") + geom_point(color = \"blue\") +\n",
    "      labs(title = \"Bayesian Optimization Progress\",\n",
    "           x = \"Iteration\", y = \"Best Gain\") +\n",
    "      theme_minimal() +\n",
    "      # Format y-axis to avoid scientific notation\n",
    "      scale_y_continuous(labels = scales::comma)\n",
    "    \n",
    "    # Chart 2: la curva de ganancia en las mejores 10 iteraciones\n",
    "    top_iters <- best_by_iter[order(-best_gain)][1:min(10, .N), iter]\n",
    "    top_data <- all_iter_data[iter %in% top_iters]\n",
    "    \n",
    "    # Add explicit envios column\n",
    "    top_data[, envios := 1:.N, by = iter]\n",
    "    \n",
    "    # Calculate y-axis limits based on the focused range\n",
    "    y_range_data <- top_data[envios >= 3000 & envios <= 25000]\n",
    "    y_min <- floor(min(y_range_data$gan_meseta, na.rm = TRUE) / 10000) * 10000\n",
    "    y_max <- ceiling(max(y_range_data$gan_meseta, na.rm = TRUE) / 10000) * 10000\n",
    "    \n",
    "    p_top <- ggplot(top_data, aes(x = envios, y = gan_meseta, color = as.factor(iter))) +\n",
    "      geom_line(na.rm = TRUE) +\n",
    "      labs(title = \"Gain Curves - Top 10 Iterations\",\n",
    "           x = \"Submissions\", y = \"Smoothed Gain\") +\n",
    "      theme_minimal() +\n",
    "      scale_color_discrete(name = \"Iteration\") +\n",
    "      # Focus on relevant submission range\n",
    "      coord_cartesian(xlim = c(3000, 25000), ylim = c(y_min, y_max)) +\n",
    "      # Format both axes nicely\n",
    "      scale_x_continuous(breaks = seq(5000, 25000, 5000), labels = scales::comma) +\n",
    "      scale_y_continuous(labels = scales::comma, \n",
    "                         breaks = seq(y_min, y_max, length.out = 6))\n",
    "    \n",
    "    # Guardar\n",
    "    ggsave(\"bayesian_optimization_results.png\",\n",
    "           arrangeGrob(p_evolution, p_top, ncol = 2), \n",
    "           width = 14, height = 7)\n",
    "    \n",
    "    return(all_iter_data)\n",
    "  } else {\n",
    "    cat(\"No gain data files found!\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "}\n",
    "# Correr\n",
    "if(exists(\"bayesiana_salida\")) {\n",
    "  final_gain_data <- generate_final_charts()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202108} , que no tiene clase\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los treinta meses del intervalo [201901, 202106]\n",
    "* Se realiza undersampling al 10%\n",
    "* Se utilizan los hiperparámetros optimos encontrados en la Bayesian Optimization\n",
    "   * Se escala min_data_in_leaf\n",
    "\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$train_final$future <- c(202106)\n",
    "\n",
    "PARAM$train_final$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104\n",
    ")\n",
    "\n",
    "PARAM$train_final$undersampling <- 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$training]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptacion Hiperparametros Optimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solamente escalo min_data_in_leaf  por  nrow(dataset_train_final) / nrow(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# leo el archivo donde quedaron los hiperparametros optimos\n",
    "tb_BO <-  fread(\"BO_log.txt\")\n",
    "setorder( tb_BO, -metrica)  # ordeno por metrica descendente\n",
    "tb_BO[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# en la tabla ademas de los parametros del LightGBM, hay campos de salida\n",
    "param_lgbm <- union( names(PARAM$lgbm$param_fijos),  names(PARAM$hipeparametertuning$hs$pars) )\n",
    "\n",
    "PARAM$train_final$param_mejores <- as.list( tb_BO[1, param_lgbm, with=FALSE])\n",
    "\n",
    "PARAM$train_final$param_mejores$min_data_in_leaf <- as.integer( round(PARAM$train_final$param_mejores$min_data_in_leaf * nrow(dataset_train_final[training == 1L]) / nrow(dtrain)))\n",
    "\n",
    "cat( tb_BO[1, min_data_in_leaf] , PARAM$train_final$param_mejores$min_data_in_leaf, \"\\n\")\n",
    "PARAM$train_final$param_mejores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui SIEMPRE voy a hacer un semillerio, independientemente de si en la Bayesian Optimization calculé un semillerio en cada iteración.\n",
    "<br> Entreno un LightGBM para cada semilla,  y guardo el modelo dentro de la carpeta  **modelitos**\n",
    "<br> Intencionalmente en una primera etapá se generan los modelos y graban, y en una segunda etapa se leen eso modelos y se aplican a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Semillerio Final\n",
    "PARAM$train_final$ksemillerio  <- 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "PARAM$train_final$semillas <- sample(primos)[seq( PARAM$train_final$ksemillerio )]\n",
    "PARAM$train_final$semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en formato LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xElu4s5W4rX7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero los modelitos\n",
    "dir.create( \"modelitos\", showWarnings= FALSE)\n",
    "\n",
    "param_completo <- copy( PARAM$train_final$param_mejores)\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( !file.exists( arch_modelo ) )\n",
    "  {\n",
    "    param_completo$seed <- sem\n",
    "\n",
    "    modelito <- lgb.train(\n",
    "      data= dtrain_final,\n",
    "      param= param_completo\n",
    "    )\n",
    "\n",
    "    lgb.save( modelito, filename= arch_modelo)\n",
    "    rm(modelito)\n",
    "     gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$train_final$future ]\n",
    "mfuture <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "vpred_acum <- rep(0.0, nrow(dfuture))\n",
    "qacumulados <- 0\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( file.exists( arch_modelo ) )\n",
    "  {\n",
    "    modelo_final <- lgb.load(arch_modelo) # leo del disco\n",
    "    #hago el predict() y acumulo\n",
    "    vpred_acum <- vpred_acum + predict(modelo_final, mfuture)\n",
    "    qacumulados <- qacumulados + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "vpred_acum <- vpred_acum / qacumulados  # paso a probabildiad\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero archivos con los \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings = FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "# lista de envios a generar\n",
    "envios_lista <- c(9000, 10000, 11000)\n",
    "\n",
    "for (envios in envios_lista) {\n",
    "  # reset Predicted column to 0 for all rows\n",
    "  tb_prediccion[, Predicted := 0L]\n",
    "  \n",
    "  # marco los primeros 'envios' registros como 1\n",
    "  tb_prediccion[1:envios, Predicted := 1L]\n",
    "  \n",
    "  # nombre del archivo\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "  \n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "         file = archivo_kaggle,\n",
    "         sep = \",\"\n",
    "  )\n",
    "  \n",
    "  # mensaje de confirmación\n",
    "  message(\"Archivo generado: \", archivo_kaggle)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# subida automática a Kaggle para múltiples archivos\n",
    "\n",
    "comando <- \"kaggle competitions submit\"\n",
    "UBA_comp <- \"-c test-202106\"\n",
    "\n",
    "# lista de envios a generar y enviar\n",
    "envios_lista <- c(9000, 10000, 11000)\n",
    "\n",
    "for (envios in envios_lista) {\n",
    "  # nombre del archivo\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "  \n",
    "  # verificar que el archivo existe antes de enviar\n",
    "  if (file.exists(archivo_kaggle)) {\n",
    "    arch <- paste(\"-f\", archivo_kaggle)\n",
    "    \n",
    "    mensaje <- paste0(\"-m \\\"under=\", PARAM$train_final$undersampling,\n",
    "      \"  cana=\", PARAM$qcanaritos,\n",
    "      \"  gb=\", PARAM$lgbm$gradient_bound,\n",
    "      \"  ff=\", PARAM$lgbm$feature_fraction,\n",
    "      \"  mdil=\", PARAM$lgbm$min_data_in_leaf,\n",
    "      \"  lr=\", PARAM$lgbm$learning_rate,\n",
    "      \"  envios=\", envios, \"\\\"\"  # agregué el número de envíos al mensaje\n",
    "    )\n",
    "    \n",
    "    linea <- paste(comando, UBA_comp, arch, mensaje)\n",
    "    salida <- system(linea, intern = TRUE)\n",
    "    \n",
    "    cat(\"Enviando archivo:\", archivo_kaggle, \"\\n\")\n",
    "    cat(salida, \"\\n\")\n",
    "    cat(\"----------------------------------------\\n\")\n",
    "  } else {\n",
    "    cat(\"Advertencia: El archivo\", archivo_kaggle, \"no existe\\n\")\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
