{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Wokflow con Full Bayesiana "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "Se muestra el workflow con la Bayesian Optimization diseñada para que LightGBM maximice la ganancia en pesos argentinos\n",
    "<br> En la Primera Competencia se maximizo la metrica global ROC AUC,  ahora pasamos a la metrica real que llamamos ganancia y que solo se concentra en los  11000 registros con mayor probabilidad de  {\"BAJA+1\",\"BAJA+2\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intencionalmente este notebook es un *semi-esqueleto*  al que usted deberá completar reutilizando código que ya generó para la Primera Competencia y nuevo código que resuelva las problemáticas presentes en esta competencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"2.1\"\n",
    "PARAM$semilla_primigenia <- 450343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "setwd('/Users/manumoreira/Repos/dmeyf2025/competencia2/')\n",
    "BASE_PATH <- getwd()\n",
    "DATA_PATH <- \"../../data/competencia_02_crudo.csv.gz\"\n",
    "\n",
    "exp_name <- sprintf(\"exp%s_seed_%d\", PARAM$experimento, PARAM$semilla_primigenia)\n",
    "exp_dir <- file.path(BASE_PATH, \"results\", exp_name)\n",
    "dir.create(exp_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "setwd(exp_dir)\n",
    "\n",
    "#cat(\"Working directory:\", getwd(), \"\\n\")\n",
    "#setwd(\"/content/buckets/b1/exp\")\n",
    "#experimento_folder <- PARAM$experimento\n",
    "#dir.create(experimento_folder, showWarnings=FALSE)\n",
    "#setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P863YZB9R1Ua",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(DATA_PATH)\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "  \"pos\" = .I,\n",
    "  numero_de_cliente,\n",
    "  periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 )\n",
    "]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "  shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente\n",
    "]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "  ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "  clase_ternaria := \"BAJA+1\"\n",
    "]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "  & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "  clase_ternaria := \"BAJA+2\"\n",
    "]\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "rm(dsimple)\n",
    "gc()\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
    "dataset[, .N, list(foto_mes, clase_ternaria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completar a gusto LUEGO de realizar un analisis exploratorio de datos.\n",
    "<br> No necesariamente en esta Segunda Competencia conviele eliminar los mismos campos que en la Primera ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deben reparar los atributos del dataset que para un cierto mes TODOS sus valores son cero.\n",
    "<br> Relevar en forma muy minuciosa en el dataset cuales son los  <atributo,mes> que estan dañados.\n",
    "<br> Algunas alternativas de solución son:\n",
    "* No hacer absolutamente nada, dejar el valor 0 tal cual está, a sabiendas que es incorrecto\n",
    "* Reemplazar esos valores dañados por  NA\n",
    "* Interpolar cada valor dañado por el valor del mes previo y el posterior\n",
    "* Calcularlo a partir de un modelo, libreria  MICE\n",
    "\n",
    "a este codigo de Data Quality  lo debera escribir usted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Drifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe corregir el drifting natural que ocurre en loa datos, en particular los datos monetarios que se vieron fuertemente afectados por una alta inflación\n",
    "<br> Posibles métodos son:\n",
    "* No hacer absolutamente nada\n",
    "* Ajuste de valores monetarios por indices del tipo :\n",
    "   * IPC  Indice de Precios al Consumidor\n",
    "   * Dolar Oficial\n",
    "   * Dolar Blue\n",
    "   * UVA  Unidad de Valor Adquisitivo\n",
    "\n",
    "a este codigo de Data Drifting lo debera escribir usted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Intra-Mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear variables nuevas a partir de las existentes dentro del mismo registro, **sin** ir a buscar información histórica.\n",
    "<br> El siguiente código es un mínimo ejemplo, agregar nuevos features a gusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# el mes 1,2, ..12 , podria servir para detectar estacionalidad\n",
    "dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# creo un ctr_quarter que tenga en cuenta cuando\n",
    "# los clientes hace 3 menos meses que estan\n",
    "# ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
    "dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
    "dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5.0]\n",
    "dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2.0]\n",
    "dataset[cliente_antiguedad == 3, ctrx_quarter_normalizado := ctrx_quarter * 1.2]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda, se perdió el link\n",
    "dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
    "require(\"Rcpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se calculan para los 6 meses previos el minimo, maximo y\n",
    "#  tendencia calculada con cuadrados minimos\n",
    "# la formula de calculo de la tendencia puede verse en\n",
    "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
    "# y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) )\n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      {\n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ;\n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ;\n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas <- function(\n",
    "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
    "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
    "    ratioavg = FALSE, ratiomax = FALSE) {\n",
    "  gc(verbose= FALSE)\n",
    "  # Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion <- ventana\n",
    "\n",
    "  last <- nrow(dataset)\n",
    "\n",
    "  # creo el vector_desde que indica cada ventana\n",
    "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids <- dataset[ , numero_de_cliente ]\n",
    "\n",
    "  vector_desde <- seq(\n",
    "    -ventana_regresion + 2,\n",
    "    nrow(dataset) - ventana_regresion + 1\n",
    "  )\n",
    "\n",
    "  vector_desde[1:ventana_regresion] <- 1\n",
    "\n",
    "  for (i in 2:last) {\n",
    "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
    "      vector_desde[i] <- i\n",
    "    }\n",
    "  }\n",
    "  for (i in 2:last) {\n",
    "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
    "      vector_desde[i] <- vector_desde[i - 1]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for (campo in cols) {\n",
    "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
    "\n",
    "    if (tendencia) {\n",
    "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
    "        nueva_col[(0 * last + 1):(1 * last)]]\n",
    "    }\n",
    "\n",
    "    if (minimo) {\n",
    "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
    "        nueva_col[(1 * last + 1):(2 * last)]]\n",
    "    }\n",
    "\n",
    "    if (maximo) {\n",
    "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
    "        nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "\n",
    "    if (promedio) {\n",
    "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
    "        nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratioavg) {\n",
    "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
    "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
    "    }\n",
    "\n",
    "    if (ratiomax) {\n",
    "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
    "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# parametros de Feature Engineering Historico de Tendencias\n",
    "PARAM$FE_hist$Tendencias$run <- TRUE\n",
    "PARAM$FE_hist$Tendencias$ventana <- 6\n",
    "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
    "PARAM$FE_hist$Tendencias$minimo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$maximo <- FALSE\n",
    "PARAM$FE_hist$Tendencias$promedio <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratioavg <- FALSE\n",
    "PARAM$FE_hist$Tendencias$ratiomax <- FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aqui se agregan las tendencias de los ultimos 6 meses\n",
    "\n",
    "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "if( PARAM$FE_hist$Tendencias$run) {\n",
    "    TendenciaYmuchomas(dataset,\n",
    "    cols = cols_lagueables,\n",
    "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
    "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
    "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
    "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
    "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
    "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
    "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
    "  )\n",
    "}\n",
    "\n",
    "ncol(dataset)\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering a partir de hojas de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add memory monitoring at the beginning\n",
    "monitor_memory <- function() {\n",
    "  if (Sys.info()[\"sysname\"] == \"Darwin\") {  # macOS\n",
    "    mem_info <- system(\"vm_stat\", intern = TRUE)\n",
    "    cat(\"Memory info:\\n\")\n",
    "    cat(mem_info[1:10], sep = \"\\n\")\n",
    "  }\n",
    "  print(gc())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "AgregaVarRandomForest <- function() {\n",
    "\n",
    "  monitor_memory()\n",
    "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
    "  gc(verbose= FALSE)\n",
    "  dataset[, clase01 := 0L ]\n",
    "  dataset[ clase_ternaria %in% c( \"BAJA+2\", \"BAJA+1\"),\n",
    "      clase01 := 1L ]\n",
    "\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c( \"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "\n",
    "  dataset[, entrenamiento :=\n",
    "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
    "\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
    "    label = dataset[entrenamiento == TRUE, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "\n",
    "  modelo <- lgb.train(\n",
    "     data = dtrain,\n",
    "     param = PARAM$FE_rf$lgb_param,\n",
    "     verbose = -100\n",
    "  )\n",
    "\n",
    "  cat( \"Fin construccion RandomForest\\n\" )\n",
    "  # grabo el modelo, achivo .model\n",
    "  lgb.save(modelo, file=\"modelo.model\" )\n",
    "\n",
    "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
    "\n",
    "  periodos <- dataset[ , unique( foto_mes ) ]\n",
    "\n",
    "  for( periodo in  periodos )\n",
    "  {\n",
    "    cat( \"periodo = \", periodo, \"\\n\" )\n",
    "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
    "\n",
    "    cat( \"Inicio prediccion\\n\" )\n",
    "    prediccion <- predict(\n",
    "        modelo,\n",
    "        datamatrix,\n",
    "        type = \"leaf\"\n",
    "    )\n",
    "    cat( \"Fin prediccion\\n\" )\n",
    "\n",
    "    for( arbolito in 1:qarbolitos )\n",
    "    {\n",
    "       cat( arbolito, \" \" )\n",
    "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
    "\n",
    "       for (pos in 1:length(hojas_arbol)) {\n",
    "         # el numero de nodo de la hoja, estan salteados\n",
    "         nodo_id <- hojas_arbol[pos]\n",
    "         dataset[ foto_mes== periodo, paste0(\n",
    "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
    "             \"_\", sprintf(\"%03d\", nodo_id)\n",
    "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
    "\n",
    "       }\n",
    "\n",
    "       rm( hojas_arbol )\n",
    "    }\n",
    "    cat( \"\\n\" )\n",
    "\n",
    "    rm( prediccion )\n",
    "    rm( datamatrix )\n",
    "    gc(verbose= FALSE)\n",
    "  }\n",
    "\n",
    "  gc(verbose= FALSE)\n",
    "\n",
    "  # borro clase01 , no debe ensuciar el dataset\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
    "\n",
    "# Estos CUATRO parametros son los que se deben modificar\n",
    "PARAM$FE_rf$arbolitos= 20\n",
    "PARAM$FE_rf$hojas_por_arbol= 16\n",
    "PARAM$FE_rf$datos_por_hoja= 100\n",
    "PARAM$FE_rf$mtry_ratio= 0.2\n",
    "\n",
    "# Estos son quasi fijos\n",
    "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
    "\n",
    "# Estos TAMBIEN son quasi fijos\n",
    "PARAM$FE_rf$lgb_param <-list(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = PARAM$FE_rf$arbolitos,\n",
    "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
    "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
    "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1.0,\n",
    "    feature_fraction = 1.0,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31L,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    force_row_wise = TRUE,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1L,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = FALSE,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = FALSE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering agregando variables de Random Forest\n",
    "#  aqui es donde se hace el trabajo\n",
    "AgregaVarRandomForest()\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ncol(dataset)\n",
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduccion dimensionalidad con canaritos asesinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intencionalmente este código no se brinda\n",
    "<br> El objetivo de esto es reducir la dimensionalidad del dataset unicamente para que la Bayesian Optimization corra mas rápido\n",
    "<br> Tambien se puede probar con Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
    "\n",
    "* future = 202108  obviamente completo\n",
    "\n",
    "* final_train =  [201901, 202106] sin undersampling de los CONTINUA\n",
    "\n",
    "* training\n",
    "   * testing = 202106\n",
    "   * training = [201901, 202104]  donde se consideran el 5% de los CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$testing <- c(202106)\n",
    "\n",
    "PARAM$trainingstrategy$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104\n",
    ")\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.05\n",
    "\n",
    "\n",
    "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# los campos en los que se entrena\n",
    "campos_buenos <- copy( setdiff(\n",
    "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros  cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "\n",
    "dataset[  foto_mes %in%  PARAM$trainingstrategy$training &\n",
    "  (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se optimizan los hiperparámetros maximizando la ganancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
    "  label= dataset[training == 1L, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain), \"columnas\", ncol(dtrain), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos de testing\n",
    "dataset_test <- dataset[foto_mes %in% PARAM$trainingstrategy$testing]\n",
    "\n",
    "# precalculo el campo de la ganancia\n",
    "dataset_test[, gan := -20000.0 ]\n",
    "dataset_test[ clase_ternaria==\"BAJA+2\", gan := 780000]\n",
    "\n",
    "# precalculo la test_matrix\n",
    "test_matrix <- data.matrix(dataset_test[, campos_buenos, with= FALSE])\n",
    "\n",
    "cat(\"filas\", nrow(dataset_test), \"columnas\", ncol(dataset_test), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Especificacion de la cantidad de iteraciones de la Bayesian Optimization\n",
    "# 50 es razonable\n",
    "PARAM$hipeparametertuning$BO_iteraciones <- 30 # un 50 seria mas razonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  extra_trees = FALSE,\n",
    "\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  max_bin= 31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Notar que se recorren algunos hiperparametros en forma logaritmica\n",
    "#   y que con forbidden se tiene en cuenta el juego que hay entre min_data_in_leaf y num_leaves\n",
    "\n",
    "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
    "  makeNumericParam(\"num_iterations\", lower= 0.0, upper= 11.1, trafo= function(x) as.integer( round(2^x)) ),\n",
    "  makeNumericParam(\"learning_rate\", lower= -8.0, upper= -1.0, trafo= function(x) 2^x ),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.05, upper= 1.0 ),\n",
    "  makeNumericParam(\"min_data_in_leaf\", lower= 0.0, upper= log2(nrow(dtrain)/2), trafo= function(x) as.integer(round(2^x)) ),\n",
    "  makeNumericParam(\"num_leaves\", lower= 1.0, upper= 10.0, trafo= function(x) as.integer(round(2^x)) ),\n",
    "  forbidden= quote( (2^min_data_in_leaf)*(2^num_leaves) > nrow(dtrain) )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro **ksemillerio** indica se se hace semillerio DENTRO de la bayesiana\n",
    "* 1 **no** se hace Ensemble Semillerio, apenas se corre un solo LightGBM\n",
    "* mayor a 1, se hace un  k-Ensemble Semillerio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro  **repe** indica si dentro de la bayesiana se toman varias medidas y luego se promedian\n",
    "<br> Esto se hace ya sea que se llama a un solo LightGBM o se haceun Ensemble Semillerio de LightGBMs\n",
    "<br> Tener en cuenta que repe multiplica linealmente el tiempo de corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$hipeparametertuning$ksemillerio <- 1L\n",
    "PARAM$hipeparametertuning$repe <- 1L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "# me quedo con PARAM$semillerio  primos al azar\n",
    "PARAM$BO$semillas <- sample(primos)[seq( PARAM$hipeparametertuning$ksemillerio * PARAM$hipeparametertuning$repe )]\n",
    "\n",
    "cat( PARAM$BO$semillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if(!require(\"rlist\")) install.packages(\"rlist\")\n",
    "require(\"rlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# logueo al archivo BO_log.txt\n",
    "loguear  <- function( reg, arch=NA, verbose=TRUE )\n",
    "{\n",
    "  t0 <- Sys.time()\n",
    "  archivo <- arch\n",
    "  if( is.na(arch) ) archivo <- paste0( folder, substitute( reg), ext )\n",
    "\n",
    "\n",
    "  if( !file.exists( archivo ) )\n",
    "  {\n",
    "    # Escribo los titulos\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  # escribo el registro\n",
    "  linea  <- paste0( format(t0, \"%Y%m%d.%H%M%S\"),  \"\\t\",     # la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  # grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   # imprimo por pantalla\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# esto esta en una funcion para que el garbage collector lo libere\n",
    "# entrena, aplica el modelo a testing, y devuelve el vector de probabilidades\n",
    "\n",
    "OneTrainPredict <- function(param_completo) {\n",
    "    \n",
    "  modelo <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_completo\n",
    "  )\n",
    "  gmodelo <<- modelo\n",
    "\n",
    "  # aplico el modelo a los datos nuevos\n",
    "  pred <- predict(\n",
    "    modelo,\n",
    "    test_matrix\n",
    "  )\n",
    "\n",
    "  return( pred )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la ganancia en datos de testing\n",
    "\n",
    "# aqui se ira guardando la mejor iteracion de la bayesiana\n",
    "gmejor <- list()\n",
    "gmejor$iter <- 0\n",
    "gmejor$gan <- -Inf\n",
    "\n",
    "giter <- 0\n",
    "if( file.exists(\"BO_log.txt\") ){\n",
    "  tb_BO <- fread(\"BO_log.txt\")\n",
    "  giter <- nrow(tb_BO) -1 \n",
    "}\n",
    "\n",
    "EstimarGanancia_lightgbm <- function(x) {\n",
    "\n",
    "  giter <<- giter + 1\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  vgan_mesetas <- c()  # las ganancias, tengo repe de ellas\n",
    "\n",
    "  # loop de las repeticionies\n",
    "  for( repe in seq( PARAM$hipeparametertuning$repe ) )\n",
    "  {\n",
    "     desde <- (PARAM$hipeparametertuning$repe-1)*PARAM$hipeparametertuning$ksemillerio + 1\n",
    "     hasta <- desde + PARAM$hipeparametertuning$ksemillerio -1\n",
    "     rsemillas <- PARAM$BO$semillas[ desde:hasta ]\n",
    "\n",
    "     # vector inicial de probabilidades\n",
    "     vpred_acum <- rep( 0.0, nrow(dataset_test) )\n",
    "\n",
    "     # loop del semillerio\n",
    "     for( sem in rsemillas ) # itero semillerio\n",
    "     {\n",
    "        param_completo$seed <- sem  # asigno se semilla\n",
    "        vpred_acum <- vpred_acum + OneTrainPredict( param_completo )\n",
    "        \n",
    "        gc(full= TRUE, verbose= FALSE)\n",
    "     }\n",
    "\n",
    "     # Calculo de ganancia suavizada de la meseta\n",
    "     tb_prediccion <- dataset_test[, list(gan)]\n",
    "     tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "     setorder(tb_prediccion, -prob)\n",
    "     tb_prediccion[, gan_acum := cumsum(gan)]\n",
    "\n",
    "     # la meseta es un punto, mil para la izquierda, otros mil para la derecha\n",
    "     tb_prediccion[, gan_meseta :=\n",
    "       frollmean(\n",
    "         x= gan_acum, n= 2001, align= \"center\",\n",
    "         na.rm= TRUE, hasNA= TRUE\n",
    "      )\n",
    "     ]\n",
    "\n",
    "     vgan_mesetas <- c(vgan_mesetas, tb_prediccion[, max(gan_meseta, na.rm = TRUE)] )\n",
    "  }\n",
    "\n",
    "  gan_mesetas_prom <- mean( vgan_mesetas ) \n",
    "\n",
    "  if( gan_mesetas_prom > gmejor$gan ){\n",
    "    gmejor$gan <<- gan_mesetas_prom\n",
    "    gmejor$iter <<- giter\n",
    "\n",
    "    # hrabo importancia de variables\n",
    "    fwrite( lgb.importance(gmodelo),\n",
    "      file= paste0(\"impo_\", giter, \".txt\"),\n",
    "      sep= \"\\t\"\n",
    "    )\n",
    "  }\n",
    "\n",
    "  # datos qeu voy a loguear\n",
    "  xx <- copy(param_completo)\n",
    "  xx$iter <- giter\n",
    "  xx$metrica_mejor <- gmejor$gan\n",
    "  xx$metrica_sd <- sd(vgan_mesetas)\n",
    "  xx$metrica <- gan_mesetas_prom\n",
    "\n",
    "  loguear( xx, \"BO_log.txt\")\n",
    "  set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")  # le reordeno a mlrMBO\n",
    "\n",
    "  return( gan_mesetas_prom ) #tiempo_corrida) )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "#  es compleja la configuracion de una Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hipeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hipeparametertuning$BO_iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrida de la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202108} , que no tiene clase\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los treinta meses del intervalo [201901, 202106]\n",
    "* Se realiza undersampling al 10%\n",
    "* Se utilizan los hiperparámetros optimos encontrados en la Bayesian Optimization\n",
    "   * Se escala min_data_in_leaf\n",
    "\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM$train_final$future <- c(202108)\n",
    "\n",
    "PARAM$train_final$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104, 202105, 202106\n",
    ")\n",
    "\n",
    "PARAM$train_final$undersampling <- 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$training]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registros cambio las proporciones de POS/NEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptacion Hiperparametros Optimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solamente escalo min_data_in_leaf  por  nrow(dataset_train_final) / nrow(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# leo el archivo donde quedaron los hiperparametros optimos\n",
    "tb_BO <-  fread(\"BO_log.txt\")\n",
    "setorder( tb_BO, -metrica)  # ordeno por metrica descendente\n",
    "tb_BO[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# en la tabla ademas de los parametros del LightGBM, hay campos de salida\n",
    "param_lgbm <- union( names(PARAM$lgbm$param_fijos),  names(PARAM$hipeparametertuning$hs$pars) )\n",
    "\n",
    "PARAM$train_final$param_mejores <- as.list( tb_BO[1, param_lgbm, with=FALSE])\n",
    "\n",
    "PARAM$train_final$param_mejores$min_data_in_leaf <- as.integer( round(PARAM$train_final$param_mejores$min_data_in_leaf * nrow(dataset_train_final[training == 1L]) / nrow(dtrain)))\n",
    "\n",
    "cat( tb_BO[1, min_data_in_leaf] , PARAM$train_final$param_mejores$min_data_in_leaf, \"\\n\")\n",
    "PARAM$train_final$param_mejores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui SIEMPRE voy a hacer un semillerio, independientemente de si en la Bayesian Optimization calculé un semillerio en cada iteración.\n",
    "<br> Entreno un LightGBM para cada semilla,  y guardo el modelo dentro de la carpeta  **modelitos**\n",
    "<br> Intencionalmente en una primera etapá se generan los modelos y graban, y en una segunda etapa se leen eso modelos y se aplican a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Semillerio Final\n",
    "PARAM$train_final$ksemillerio  <- 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "PARAM$train_final$semillas <- sample(primos)[seq( PARAM$train_final$ksemillerio )]\n",
    "PARAM$train_final$semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dejo los datos en formato LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xElu4s5W4rX7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero los modelitos\n",
    "dir.create( \"modelitos\", showWarnings= FALSE)\n",
    "\n",
    "param_completo <- copy( PARAM$train_final$param_mejores)\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( !file.exists( arch_modelo ) )\n",
    "  {\n",
    "    param_completo$seed <- sem\n",
    "\n",
    "    modelito <- lgb.train(\n",
    "      data= dtrain_final,\n",
    "      param= param_completo\n",
    "    )\n",
    "\n",
    "    lgb.save( modelito, filename= arch_modelo)\n",
    "    rm(modelito)\n",
    "     gc()\n",
    "  }\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$train_final$future ]\n",
    "mfuture <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "vpred_acum <- rep(0.0, nrow(dfuture))\n",
    "qacumulados <- 0\n",
    "\n",
    "for( sem in PARAM$train_final$semillas ) {\n",
    "\n",
    "  arch_modelo <- paste0(\"./modelitos/mod_\", sem, \".txt\")\n",
    "  if( file.exists( arch_modelo ) )\n",
    "  {\n",
    "    modelo_final <- lgb.load(arch_modelo) # leo del disco\n",
    "    #hago el predict() y acumulo\n",
    "    vpred_acum <- vpred_acum + predict(modelo_final, mfuture)\n",
    "    qacumulados <- qacumulados + 1\n",
    "  }\n",
    "}\n",
    "\n",
    "vpred_acum <- vpred_acum / qacumulados  # paso a probabildiad\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJwg7LHd11yu",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := vpred_acum ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWW3tatE12je",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "envios <- 11000\n",
    "tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zA_W25c15DP",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Sys.time()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
