{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Linea de Muerte Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "* Preprocesamiento\n",
    "   * Se quitan del datataset los *envenenados* atributos  mprestamos_personales y cprestamos_personales\n",
    "   * Se agregan lags y delta_lags de orden 1 y 2\n",
    "* Modelado no se optimizan hiperarámetros\n",
    "* Produccion\n",
    "   * Entrenamieento final\n",
    "      * Se entrena en {202101, 202102, 202103, 202104}\n",
    "      * Se hace un **muy agresivo** undersampling de **0.10** de los \"CONTINUA\"\n",
    "      * POS = {\"BAJA+1\", \"BAJA+2\"}\n",
    "      * librería  *zLightGBM*\n",
    "         * **50** canaritos se agregan al comienzo del dataset\n",
    "         * gradient_bound se deja en su default de  **0.1**\n",
    "   * Clasificacion\n",
    "      * Se corta en 11000  envios\n",
    "\n",
    "---\n",
    "Resultados :\n",
    "* ganancia de 383.371 M en el Private Leaderboard ( 11.000 en el Public )\n",
    "* utiliza 12 GB de memoria RAM\n",
    "* corre en  6 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 09:35:37 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 x 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 660709</td><td>35.3</td><td>1462257</td><td>78.1</td><td>   NA</td><td>1073932</td><td>57.4</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1228649</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>32768</td><td>2010932</td><td>15.4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 x 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  660709 & 35.3 & 1462257 & 78.1 &    NA & 1073932 & 57.4\\\\\n",
       "\tVcells & 1228649 &  9.4 & 8388608 & 64.0 & 32768 & 2010932 & 15.4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 x 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |  660709 | 35.3 | 1462257 | 78.1 |    NA | 1073932 | 57.4 |\n",
       "| Vcells | 1228649 |  9.4 | 8388608 | 64.0 | 32768 | 2010932 | 15.4 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) limit (Mb) max used (Mb)\n",
       "Ncells  660709 35.3 1462257    78.1    NA      1073932  57.4\n",
       "Vcells 1228649  9.4 8388608    64.0 32768      2010932  15.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "Sys.time()\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"zmuerte-25-UVA\"\n",
    "PARAM$semilla_primigenia <- 450343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/manumoreira/Repos/dmeyf2025/competencia2/results/expzmuerte-10-manu_seed_450343 \n"
     ]
    }
   ],
   "source": [
    "#setwd('/Users/manumoreira/Repos/dmeyf2025/competencia2/')\n",
    "#BASE_PATH <- getwd()\n",
    "#DATA_PATH <- \"../../data/competencia_02_crudo.csv.gz\"\n",
    "\n",
    "#exp_name <- sprintf(\"exp%s_seed_%d\", PARAM$experimento, PARAM$semilla_primigenia)\n",
    "#exp_dir <- file.path(BASE_PATH, \"results\", exp_name)\n",
    "#dir.create(exp_dir, recursive = TRUE, showWarnings = FALSE)\n",
    "#setwd(exp_dir)\n",
    "\n",
    "cat(\"Working directory:\", getwd(), \"\\n\")\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- PARAM$experimento\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))\n",
    "DATA_PATH = \"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/competencia_01_crudo.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "### Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P863YZB9R1Ua",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 09:56:35 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 x 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>   770964</td><td>  41.2</td><td>   1462257</td><td>  78.1</td><td>   NA</td><td>  1462257</td><td>  78.1</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>722154630</td><td>5509.7</td><td>1017411198</td><td>7762.3</td><td>32768</td><td>846003906</td><td>6454.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 x 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &    770964 &   41.2 &    1462257 &   78.1 &    NA &   1462257 &   78.1\\\\\n",
       "\tVcells & 722154630 & 5509.7 & 1017411198 & 7762.3 & 32768 & 846003906 & 6454.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 x 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |    770964 |   41.2 |    1462257 |   78.1 |    NA |   1462257 |   78.1 |\n",
       "| Vcells | 722154630 | 5509.7 | 1017411198 | 7762.3 | 32768 | 846003906 | 6454.5 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)   gc trigger (Mb)   limit (Mb) max used  (Mb)  \n",
       "Ncells    770964   41.2    1462257   78.1    NA        1462257   78.1\n",
       "Vcells 722154630 5509.7 1017411198 7762.3 32768      846003906 6454.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 09:56:45 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()\n",
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(DATA_PATH)\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "  \"pos\" = .I,\n",
    "  numero_de_cliente,\n",
    "  periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 )\n",
    "]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "  shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente\n",
    "]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "  ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "  clase_ternaria := \"BAJA+1\"\n",
    "]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "  & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "  clase_ternaria := \"BAJA+2\"\n",
    "]\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "rm(dsimple)\n",
    "gc()\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### Eliminacion de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La auténtica  **salsa mágica**  de este script es la eliminación de estos dos atributos del dataset ya que tran problemas con el Data Drifting\n",
    "* mprestamos_personales\n",
    "* cprestamos_personales\n",
    "\n",
    "el problema con estos campos se detectó manualmente mediante un analisis exploratorio de datos y análisis de corridas de LightGBM en meses previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in `[.data.table`(dataset, , `:=`(mprestamos_personales, NULL)):\n",
      "\"Tried to assign NULL to column 'mprestamos_personales', but this column does not exist to remove\"\n",
      "Warning message in `[.data.table`(dataset, , `:=`(cprestamos_personales, NULL)):\n",
      "\"Tried to assign NULL to column 'cprestamos_personales', but this column does not exist to remove\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 18:20:32 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[, mprestamos_personales := NULL ]\n",
    "dataset[, cprestamos_personales := NULL ]\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Features nuevos\n",
    "dataset[, x_margen_total := mactivos_margen + mpasivos_margen] # Entró\n",
    "dataset[, x_pct_margen_activos := mactivos_margen / pmax(margen_total, 1)] # Entró\n",
    "dataset[, x_trx_visa_por_cuenta := ctarjeta_visa_transacciones / pmax(ctarjeta_visa, 1)] # Entró\n",
    "dataset[, x_ticket_visa := mtarjeta_visa_consumo / pmax(ctarjeta_visa_transacciones, 1)] # Entró\n",
    "dataset[, x_pct_dolares := (mcaja_ahorro_dolares + mplazo_fijo_dolares + minversion1_dolares) / \n",
    "         pmax(mcuentas_saldo + mplazo_fijo_pesos + mplazo_fijo_dolares, 1)] # Entró\n",
    "dataset[, x_debitos_auto_total := ccuenta_debitos_automaticos + \n",
    "                                  ctarjeta_visa_debitos_automaticos + \n",
    "                                  ctarjeta_master_debitos_automaticos] # Entró\n",
    "dataset[, x_monto_debito_promedio := (mcuenta_debitos_automaticos + \n",
    "                                     mtarjeta_visa_debitos_automaticos + \n",
    "                                     mttarjeta_master_debitos_automaticos) / \n",
    "                                    pmax(debitos_auto_total, 1)] # Entró\n",
    "dataset[, x_patrimonio_neto := \n",
    "  (mcuentas_saldo + \n",
    "   mcaja_ahorro + mcaja_ahorro_adicional + mcaja_ahorro_dolares +\n",
    "   mcuenta_corriente + mcuenta_corriente_adicional +\n",
    "   mplazo_fijo_pesos + mplazo_fijo_dolares +\n",
    "   minversion1_pesos + minversion1_dolares + minversion2)\n",
    "  -\n",
    "  (mprestamos_prendarios + mprestamos_hipotecarios +\n",
    "   Master_msaldototal + Visa_msaldototal)]\n",
    "dataset[, x_mes := foto_mes %% 100]   \n",
    "dataset[, x_quarter := ceiling(x_mes / 3)]\n",
    "dataset[, x_lifecycle_stage := cliente_antiguedad / pmax(cliente_edad * 12, 1)]\n",
    "dataset[, x_rentabilidad_por_producto := mrentabilidad / pmax(cproductos, 1)]\n",
    "dataset[, x_product_complexity := (tcuentas + ctarjeta_visa + ctarjeta_master + cprestamos_personales + \n",
    "                                  cprestamos_hipotecarios + cseguro_vida + cseguro_auto) / 7]\n",
    "dataset[, x_liquidity_stress := (Master_delinquency + Visa_delinquency + \n",
    "                                mcomisiones_mantenimiento + mcomisiones_otras) / \n",
    "         pmax(mcuentas_saldo, 1)]\n",
    "dataset[, x_wealthy_active := x_patrimonio_neto * log1p(x_engagement_score)]\n",
    "dataset[, x_wealth_premium_behavior := x_patrimonio_neto * x_ticket_visa]\n",
    "dataset[, x_dollarized_engaged := x_pct_dolares * x_engagement_score]\n",
    "dataset[, x_wealth_automated := x_patrimonio_neto * x_debitos_auto_total]\n",
    "dataset[, x_dollar_visa_premium := x_pct_dolares * x_ticket_visa]\n",
    "dataset[, x_dollar_visa_activity := x_pct_dolares * x_trx_visa_por_cuenta]\n",
    "dataset[, x_visa_auto_premium := x_ticket_visa * x_monto_debito_promedio]\n",
    "dataset[, x_auto_premium := x_debitos_auto_total * x_ticket_visa * x_pct_margen_activos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Cargo datos UVA\n",
    "uva_dt <- fread(\"~/buckets/b1/datasets/UVA.csv\")\n",
    "uva_dt[, Fecha := as.Date(Fecha, format = \"%d/%m/%Y\")]\n",
    "uva_dt[, year_month := format(Fecha, \"%Y%m\")]\n",
    "\n",
    "# Tomo el primer valor de cada mes\n",
    "uva_first_day <- uva_dt[, .SD[1], by = year_month][, .(year_month, uva_value = Valor)]\n",
    "\n",
    "# Cast\n",
    "uva_first_day[, uva_value := as.numeric(gsub(\",\", \".\", uva_value))]\n",
    "uva_first_day[, year_month := as.character(year_month)]\n",
    "\n",
    "convert_to_uva <- function(dt, monetary_vars, uva_ref) {\n",
    "  # Create a temporary character version of foto_mes\n",
    "  temp_dt <- copy(dt)\n",
    "  temp_dt[, foto_mes_char := as.character(foto_mes)]\n",
    "  \n",
    "  # Perform the join\n",
    "  dt_result <- uva_ref[temp_dt, on = .(year_month = foto_mes_char)]\n",
    "  \n",
    "  # Create new _uva features for each monetary variable\n",
    "  for (var in monetary_vars) {\n",
    "    uva_var <- paste0(var, \"_uva\")\n",
    "    dt_result[, (uva_var) := get(var) / uva_value]\n",
    "  }\n",
    "  \n",
    "  # Remove the temporary columns\n",
    "  dt_result[, c(\"year_month\", \"uva_value\", \"foto_mes_char\") := NULL]\n",
    "  \n",
    "  return(dt_result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "monetary_vars <- c(\"mrentabilidad\", \"mrentabilidad_annual\", \"mcomisiones\", \"mactivos_margen\", \"mpasivos_margen\", \n",
    "                \"mcuenta_corriente_adicional\", \"mcuenta_corriente\", \"mcaja_ahorro\", \"mcaja_ahorro_adicional\", \n",
    "                \"mcaja_ahorro_dolares\", \"mcuentas_saldo\", \"mautoservicio\", \"mtarjeta_visa_consumo\", \"mtarjeta_master_consumo\", \n",
    "                \"mprestamos_prendarios\", \"mprestamos_hipotecarios\", \"mplazo_fijo_dolares\", \n",
    "                \"mplazo_fijo_pesos\", \"minversion1_pesos\", \"minversion1_dolares\", \"minversion2\", \"mpayroll\", \"mpayroll2\", \n",
    "                \"mcuenta_debitos_automaticos\", \"mttarjeta_visa_debitos_automaticos\", \"mttarjeta_master_debitos_automaticos\", \n",
    "                \"mpagodeservicios\", \"mpagomiscuentas\", \"mcajeros_propios_descuentos\", \"mtarjeta_visa_descuentos\", \n",
    "                \"mtarjeta_master_descuentos\", \"mcomisiones_mantenimiento\", \"mcomisiones_otras\", \"mforex_buy\", \"mforex_sell\", \n",
    "                \"mtransferencias_recibidas\", \"mtransferencias_emitidas\", \"mextraccion_autoservicio\", \"mcheques_depositados\", \n",
    "                \"mcheques_emitidos\", \"mcheques_depositados_rechazados\", \"mcheques_emitidos_rechazados\", \"matm\", \"matm_other\", \n",
    "                \"Master_mfinanciacion_limite\", \"Master_msaldototal\", \"Master_msaldopesos\", \"Master_msaldodolares\", \n",
    "                \"Master_mconsumospesos\", \"Master_mconsumosdolares\", \"Master_mlimitecompra\", \"Master_madelantopesos\", \n",
    "                \"Master_madelantodolares\", \"Master_mpagado\", \"Master_mpagospesos\", \"Master_mpagosdolares\", \n",
    "                \"Master_mconsumototal\", \"Master_mpagominimo\", \"Visa_mfinanciacion_limite\", \"Visa_msaldototal\", \n",
    "                \"Visa_msaldopesos\", \"Visa_msaldodolares\", \"Visa_mconsumospesos\", \"Visa_mconsumosdolares\", \n",
    "                \"Visa_mlimitecompra\", \"Visa_madelantopesos\", \"Visa_madelantodolares\", \"Visa_mpagado\", \"Visa_mpagospesos\", \n",
    "                \"Visa_mpagosdolares\", \"Visa_mconsumototal\", \"Visa_mpagominimo\")\n",
    "dataset <- convert_to_uva(dataset, monetary_vars, uva_first_day)\n",
    "#Borro variables originales\n",
    "dataset[, (monetary_vars) := NULL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Historico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataset crudo, se generan los lags y delta de orden 1 y 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 09:57:49 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering Historico\n",
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "))\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "  paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "  by= numero_de_cliente,\n",
    "  .SDcols= cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "  dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "  dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de Hipeparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script no hace optimización de hiperparámetros\n",
    "<br> **No** se llama a una Bayesian Optimization, ese paso se saltea.\n",
    "<br> No hace falta hacer particiones <train, validate, test>,  tampoco se hace un k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "## Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las decisiones que se toman para la construccion del modelo final son:\n",
    "* Los positvos son  POS={\"BAJA+1\", \"BAJA+2\"}, esta es una meticulosa decisión.\n",
    "* Se entrena en los cuatro meses  {202101, 202102, 202103, 202104}, esta es una meticulosa decisión.\n",
    "* Se hace un muy agresivo undersampling del **0.10** = 10% de la clase mayoritaria (los \"CONTINUA\" )\n",
    "* Obviamente los datos donde se aplica el modelo es el mes  {202106}\n",
    "* Por experimentos en meses anteriores, se decide cortar en los 11000 registros con mayor probabildiad de POS={\"BAJA+1\", \"BAJA+2\"}, , esta es una *enorme* decisión.\n",
    "* No se optmizan los hiperparámetros de LightGBM, sino que se llama a la libreria *zLightGBM*\n",
    "* Para *zLightGBM*  se crean **50** canaritos, esta es una decisión enorme !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 10:02:03 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training y future\n",
    "Sys.time()\n",
    "\n",
    "PARAM$train_final$meses <- c(202101, 202102, 202103, 202104)\n",
    "PARAM$train_final$undersampling <- 0.25\n",
    "\n",
    "PARAM$future <- c(202106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### Final Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena en los cuatro meses {202101, 202102, 202103, 202104}\n",
    "<br>Se hace un muy agresivo undersampling del 10% de la clase mayoritaria (los \"CONTINUA\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# se filtran los meses donde se entrena el modelo final\n",
    "dataset_train_final <- dataset[foto_mes %in% PARAM$train_final$meses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Undersampling, van todos los \"BAJA+1\" y \"BAJA+2\" y solo algunos \"CONTINIA\"\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train_final[, azar := runif(nrow(dataset_train_final))]\n",
    "dataset_train_final[, training := 0L]\n",
    "\n",
    "dataset_train_final[\n",
    "  (azar <= PARAM$train_final$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]\n",
    "\n",
    "dataset_train_final[, azar:= NULL] # elimino la columna azar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train_final[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: zlightgbm\n",
      "\n",
      "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
      "\"there is no package called 'zlightgbm'\"\n",
      "Warning message in install.packages(\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/zlightgbm_4.6.0.99.tar.gz\", :\n",
      "\"installation of package '/var/folders/v5/kbcdcc412tb1kkysqm2lplxm0000gq/T//RtmpaNLqy8/downloaded_packages/zlightgbm_4.6.0.99.tar.gz' had non-zero exit status\"\n",
      "Loading required package: zlightgbm\n",
      "\n",
      "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
      "\"there is no package called 'zlightgbm'\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-11-05 10:05:30 -03\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utilizo  zLightGBM  la nueva libreria\n",
    "if( !require(\"zlightgbm\") ) install.packages(\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/zlightgbm_4.6.0.99.tar.gz\", repos= NULL, type= \"source\")\n",
    "require(\"zlightgbm\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(zlightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un hiperparámetro de  *zLightGBM* es la cantidad de canaritos, en este caso se decidió (con tests realizados en {202101, 202102} fijarlo en 50\n",
    "<br> esta es una importante decisión que debe tomarse\n",
    "<br> en la version actual de *zLightGBM* los canaritos deben agregarse por fuera al dataset, y mandatoriamente deben ser las primeras columnas del mismo\n",
    "<br> durante noviembre, si hay suerte, se liberará una versiónn que lo haga automáticamente internamente en el código C++ de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 14:59:04 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# canaritos\n",
    "PARAM$qcanaritos <- 60\n",
    "\n",
    "cols0 <- copy(colnames(dataset_train_final))\n",
    "filas <- nrow(dataset_train_final)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dataset_train_final[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "# las columnas canaritos mandatoriamente van al comienzo del dataset\n",
    "cols_canaritos <- copy( setdiff( colnames(dataset_train_final), cols0 ) )\n",
    "setcolorder( dataset_train_final, c( cols_canaritos, cols0 ) )\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xElu4s5W4rX7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train_final),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PppMHcGYaaol",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filas 71714 columnas 802 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 14:59:05 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train_final[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train_final[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "cat(\"filas\", nrow(dtrain_final), \"columnas\", ncol(dtrain_final), \"\\n\")\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevos hiperparámetros en  *zLightGBM*\n",
    "* canaritos , entero >=0,  cantidad de atributos del dataset que se consideran como canaritos, mandatoriamente en la version actual deben estar al comienzo.\n",
    "* gradient_bound , numero real, >=0  cota que se pone a los scores de las hojas de los arboles, es un learning_rate adaptativo\n",
    "\n",
    "En el caso que  canaritos==0  y  gradient_bound==0  entonces  xLightGBM se comporta exactamente igual a  LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta que el hiperparámetro  min_data_in_leaf se está dejando en el valor de 20 que es el default de LightGBM\n",
    "<br> realmente valdria la pena experimentar con distintos valores de  min_data_in_leaf, hay potencial de mejora !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 14:59:05 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# definicion de parametros, los viejos y los nuevos\n",
    "\n",
    "PARAM$lgbm <-  list(\n",
    "  boosting= \"gbdt\",\n",
    "  objective= \"binary\",\n",
    "  metric= \"custom\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE,\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_bin= 31L,\n",
    "  min_data_in_leaf= 20L,  #este ya es el valor default de LightGBM\n",
    "\n",
    "  num_iterations= 9999L, # dejo libre la cantidad de arboles, zLightGBM se detiene solo\n",
    "  num_leaves= 9999L, # dejo libre la cantidad de hojas, zLightGBM sabe cuando no hacer un split\n",
    "  learning_rate= 1.0,  # se lo deja en 1.0 para que si el score esta por debajo de gradient_bound no se lo escale\n",
    "    \n",
    "  feature_fraction= 0.50, # un valor equilibrado, habra que probar alternativas ...\n",
    "    \n",
    "  canaritos= PARAM$qcanaritos, # fundamental en zLightGBM, aqui esta el control del overfitting\n",
    "  gradient_bound= 0.1  # default de zLightGBM\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se ejecuta  *zLightGBM*\n",
    "<br> no se utilizan hiperparámetros optimos para controlar el overfitting\n",
    "<br> zLightGBM  sabe cuando no hacer un split\n",
    "<br> si al hacer el n-simo arbol, no puede hacer el split de la raiz, detiene el crecimiento del ensemble y termina\n",
    "<br>\n",
    "<br> claramente el  min_data_in_leaf=20 que es el default de LightGBM esta jugando un papel importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ssk5nnMk6INK",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 15:03:22 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# entreno el modelo\n",
    "\n",
    "modelo_final <- lgb.train(\n",
    "  data= dtrain_final,\n",
    "  param= PARAM$lgbm\n",
    ")\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad arbolitos= 285 \n",
      "summary de las hojas de los arboles"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "    3.0   167.0   358.0   373.4   534.0   982.0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 15:03:32 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grabo el modelo generado, esto pude ser levantado por LighGBM en cualquier maquina\n",
    "lgb.save(modelo_final, file=\"zmodelo.txt\")\n",
    "\n",
    "# grabo un dataset que tiene el detalle de los arboles de LightGBM\n",
    "tb_arboles <- lgb.model.dt.tree(modelo_final)\n",
    "fwrite(tb_arboles, file=\"tb_arboles.txt\", sep=\"\\t\")\n",
    "\n",
    "cat(\"cantidad arbolitos=\", tb_arboles[, max(tree_index)+1],\"\\n\" )\n",
    "cat(\"summary de las hojas de los arboles\")\n",
    "summary( tb_arboles[, list(hojas=max(leaf_index, na.rm=TRUE)+1), tree_index][,hojas])\n",
    "\n",
    "Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el predict() del modelo en los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "# penosamente, en la versión actual de zLightGBM  los campos canaritos\n",
    "#  aunque no se utilizan para nada, también deben estar en el dataset donde se hace el predict()\n",
    "filas <- nrow(dfuture)\n",
    "\n",
    "for( i in seq(PARAM$qcanaritos) ){\n",
    "  dfuture[, paste0(\"canarito_\",i) := runif( filas) ]\n",
    "}\n",
    "\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RJwg7LHd11yu",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion, puede ser util para futuros ensembles\n",
    "#  ya que le modelo ganador va a ser un ensemble de LightGBMs\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "fwrite(tb_importancia, file = \"impo.txt\", sep = \"\\t\")\n",
    "\n",
    "cat(\"\\nTop 10 most important features:\\n\")\n",
    "print(head(tb_importancia, 10))\n",
    "\n",
    "# Save model\n",
    "lgb.save(modelo_final, \"modelo.txt\")\n",
    "cat(\"\\nModel and importance saved\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "### Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomó la decisión de enviar a los 11000 registros con mayor probabilidad de POS={\"BAJA+1\",\"BAJA+2\"}\n",
    "<br> esto se determinó en forma artesanal analizando meses anterior\n",
    "<br> esta es una muy importante decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gWW3tatE12je",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "envios <- 11000\n",
    "tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subida a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to DMEyF 2025 Primera"
     ]
    }
   ],
   "source": [
    "# subida automática a Kaggle, solo tiene sentido para la Primera Competencia\n",
    "\n",
    "comando <- \"kaggle competitions submit\"\n",
    "UBA_comp <- \"-c dm-ey-f-2025-primera\"\n",
    "arch <- paste(\"-f\", archivo_kaggle)\n",
    "\n",
    "mensaje <- paste0(\"-m 'under=\", PARAM$train_final$undersampling,\n",
    "  \"  cana=\", PARAM$qcanaritos,\n",
    "  \"  gb=\", PARAM$lgbm$gradient_bound,\n",
    "  \"  ff=\", PARAM$lgbm$feature_fraction,\n",
    "  \"  mdil=\", PARAM$lgbm$min_data_in_leaf,\n",
    "  \"  lr=\", PARAM$lgbm$learning_rate, \"'\"\n",
    ")\n",
    "\n",
    "linea <- paste(comando, UBA_comp, arch, mensaje)\n",
    "salida <- system(linea, intern=TRUE)\n",
    "cat(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9zA_W25c15DP",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"2025-10-31 15:03:38 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.time()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
